{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1743ab02-7c7f-45f5-8e17-070f732a0154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PyGILE-Plus initialized with 1,773+ algorithms!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Critical environment setup for 1,773 algorithms\n",
    "os.environ['LD_LIBRARY_PATH'] = \"/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/opt/conda/envs/pygile/lib\"\n",
    "os.environ['SAGA_CMD'] = '/opt/saga/bin/saga_cmd'\n",
    "os.environ['SAGA_MLB'] = '/opt/saga/lib/saga'\n",
    "os.environ['GISBASE'] = '/opt/grass'\n",
    "os.environ['OTB_APPLICATION_PATH'] = '/opt/otb/lib/otb/applications'\n",
    "\n",
    "# Add GRASS to Python path\n",
    "sys.path.insert(0, '/opt/grass/etc/python')\n",
    "\n",
    "# Initialize QGIS\n",
    "from qgis.core import QgsApplication\n",
    "QgsApplication.setPrefixPath('/opt/conda/envs/pygile', True)\n",
    "qgs = QgsApplication([], False)\n",
    "qgs.initQgis()\n",
    "\n",
    "import processing\n",
    "from processing.core.Processing import Processing\n",
    "Processing.initialize()\n",
    "\n",
    "print(\" PyGILE-Plus initialized with 1,773+ algorithms!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "384f6957-088c-47ac-b994-26fe2e64dda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAGA interface initialized\n",
      "SAGA command line working\n",
      "PySAGA-cmd interface ready with version 9.3.2\n"
     ]
    }
   ],
   "source": [
    "# SAGA GIS Integration for PyGILE-Plus Environment\n",
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "class SAGAInterface:\n",
    "    def __init__(self, saga_cmd_path=\"/opt/saga/bin/saga_cmd\"):\n",
    "        self.saga_cmd = saga_cmd_path\n",
    "        self.env = os.environ.copy()\n",
    "        self.env['SAGA_MLB'] = \"/opt/saga/lib/saga\"\n",
    "        self.env['LD_LIBRARY_PATH'] = \"/opt/saga/lib:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/opt/conda/envs/pygile/lib\"\n",
    "        \n",
    "    def run_tool(self, library, tool, parameters):\n",
    "        \"\"\"Execute SAGA tool with parameters\"\"\"\n",
    "        cmd = [self.saga_cmd, library, str(tool)] + parameters\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, env=self.env)\n",
    "        if result.returncode != 0:\n",
    "            raise RuntimeError(f\"SAGA error: {result.stderr}\")\n",
    "        return result\n",
    "    \n",
    "    def get_tools(self, library):\n",
    "        \"\"\"List available tools in library\"\"\"\n",
    "        result = subprocess.run([self.saga_cmd, library], capture_output=True, text=True, env=self.env)\n",
    "        print(f\"Available tools in {library}:\")\n",
    "        print(result.stdout)\n",
    "        \n",
    "    def morphometry_slope(self, input_dem, output_slope):\n",
    "        \"\"\"Calculate slope from DEM using morphometry library\"\"\"\n",
    "        params = [f\"-ELEVATION={input_dem}\", f\"-SLOPE={output_slope}\", \"-METHOD=4\"]\n",
    "        return self.run_tool(\"ta_morphometry\", 0, params)\n",
    "\n",
    "# Initialize SAGA interface\n",
    "saga = SAGAInterface()\n",
    "print(\"SAGA interface initialized\")\n",
    "\n",
    "# Test SAGA functionality - Fixed library path issue\n",
    "try:\n",
    "    result = subprocess.run([\"/opt/saga/bin/saga_cmd\", \"--help\"], \n",
    "                          capture_output=True, text=True, \n",
    "                          env={'LD_LIBRARY_PATH': '/opt/saga/lib:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/opt/conda/envs/pygile/lib',\n",
    "                               'SAGA_MLB': '/opt/saga/lib/saga'})\n",
    "    if result.returncode == 0:\n",
    "        print(\"SAGA command line working\")\n",
    "    else:\n",
    "        print(f\"SAGA error: {result.stderr}\")\n",
    "except Exception as e:\n",
    "    print(f\"SAGA test failed: {e}\")\n",
    "\n",
    "# Method 2: Direct subprocess approach (most reliable)\n",
    "def saga_direct(library, tool, **kwargs):\n",
    "    \"\"\"Direct SAGA execution via subprocess\"\"\"\n",
    "    cmd = [\"/opt/saga/bin/saga_cmd\", library, str(tool)]\n",
    "    for key, value in kwargs.items():\n",
    "        cmd.append(f\"-{key.upper()}={value}\")\n",
    "    \n",
    "    env = os.environ.copy()\n",
    "    env['SAGA_MLB'] = \"/opt/saga/lib/saga\"\n",
    "    \n",
    "    result = subprocess.run(cmd, capture_output=True, text=True, env=env)\n",
    "    if result.returncode == 0:\n",
    "        print(\"SAGA execution successful\")\n",
    "    return result\n",
    "\n",
    "# Method 3: PySAGA-cmd wrapper (if installed) - Fixed version\n",
    "try:\n",
    "    from PySAGA_cmd import SAGA\n",
    "    saga_py = SAGA('/opt/saga/bin/saga_cmd', version='9.3.2')\n",
    "    morphometry = saga_py / 'ta_morphometry'\n",
    "    slope_tool = morphometry / 0\n",
    "    print(\"PySAGA-cmd interface ready with version 9.3.2\")\n",
    "except ImportError:\n",
    "    print(\"PySAGA-cmd not available, using direct methods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5aaa2bd-4d54-4353-a7de-84ec304f6387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAGA interface initialized\n",
      "SAGA command line working\n",
      "Available SAGA Morphometry Tools:\n",
      "========================================\n",
      "#####   ##   #####    ##\n",
      "###     ###  ##       ###\n",
      "###   # ## ##  #### # ##\n",
      "### ##### ##    # #####\n",
      "##### #   ##  ##### #   ##\n",
      "SAGA Version: 9.3.2\n",
      "Library    : Morphometry\n",
      "Category   : Terrain Analysis\n",
      "File       : /opt/saga/lib/saga/libta_morphometry.so\n",
      "\n",
      "SAGA is ready for geospatial analysis!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SAGA GIS Integration for PyGILE-Plus Environment\n",
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "class SAGAInterface:\n",
    "    def __init__(self, saga_cmd_path=\"/opt/saga/bin/saga_cmd\"):\n",
    "        self.saga_cmd = saga_cmd_path\n",
    "        self.env = os.environ.copy()\n",
    "        self.env['SAGA_MLB'] = \"/opt/saga/lib/saga\"\n",
    "        self.env['LD_LIBRARY_PATH'] = \"/opt/saga/lib:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/opt/conda/envs/pygile/lib\"\n",
    "        \n",
    "    def run_tool(self, library, tool, parameters):\n",
    "        \"\"\"Execute SAGA tool with parameters\"\"\"\n",
    "        cmd = [self.saga_cmd, library, str(tool)] + parameters\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, env=self.env)\n",
    "        if result.returncode != 0:\n",
    "            raise RuntimeError(f\"SAGA error: {result.stderr}\")\n",
    "        return result\n",
    "    \n",
    "    def get_tools(self, library):\n",
    "        \"\"\"List available tools in library\"\"\"\n",
    "        result = subprocess.run([self.saga_cmd, library], capture_output=True, text=True, env=self.env)\n",
    "        print(f\"Available tools in {library}:\")\n",
    "        print(result.stdout)\n",
    "        \n",
    "    def morphometry_slope(self, input_dem, output_slope):\n",
    "        \"\"\"Calculate slope from DEM using morphometry library\"\"\"\n",
    "        params = [f\"-ELEVATION={input_dem}\", f\"-SLOPE={output_slope}\", \"-METHOD=4\"]\n",
    "        return self.run_tool(\"ta_morphometry\", 0, params)\n",
    "\n",
    "# Initialize SAGA interface\n",
    "saga = SAGAInterface()\n",
    "print(\"SAGA interface initialized\")\n",
    "\n",
    "# Test SAGA functionality - Fixed library path issue\n",
    "try:\n",
    "    result = subprocess.run([\"/opt/saga/bin/saga_cmd\", \"--help\"], \n",
    "                          capture_output=True, text=True, \n",
    "                          env={'LD_LIBRARY_PATH': '/opt/saga/lib:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/opt/conda/envs/pygile/lib',\n",
    "                               'SAGA_MLB': '/opt/saga/lib/saga'})\n",
    "    if result.returncode == 0:\n",
    "        print(\"SAGA command line working\")\n",
    "    else:\n",
    "        print(f\"SAGA error: {result.stderr}\")\n",
    "except Exception as e:\n",
    "    print(f\"SAGA test failed: {e}\")\n",
    "\n",
    "# Method 2: Direct subprocess approach (most reliable)\n",
    "def saga_direct(library, tool, **kwargs):\n",
    "    \"\"\"Direct SAGA execution via subprocess\"\"\"\n",
    "    cmd = [\"/opt/saga/bin/saga_cmd\", library, str(tool)]\n",
    "    for key, value in kwargs.items():\n",
    "        cmd.append(f\"-{key.upper()}={value}\")\n",
    "    \n",
    "    env = os.environ.copy()\n",
    "    env['SAGA_MLB'] = \"/opt/saga/lib/saga\"\n",
    "    \n",
    "    result = subprocess.run(cmd, capture_output=True, text=True, env=env)\n",
    "    if result.returncode == 0:\n",
    "        print(\"SAGA execution successful\")\n",
    "    return result\n",
    "\n",
    "# Quick SAGA demonstration - Terrain Analysis\n",
    "def demonstrate_saga():\n",
    "    \"\"\"Demonstrate SAGA terrain analysis capabilities\"\"\"\n",
    "    \n",
    "    # List available morphometry tools\n",
    "    result = subprocess.run([\"/opt/saga/bin/saga_cmd\", \"ta_morphometry\"], \n",
    "                          capture_output=True, text=True, \n",
    "                          env={'LD_LIBRARY_PATH': '/opt/saga/lib:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/opt/conda/envs/pygile/lib',\n",
    "                               'SAGA_MLB': '/opt/saga/lib/saga'})\n",
    "    \n",
    "    print(\"Available SAGA Morphometry Tools:\")\n",
    "    print(\"=\"*40)\n",
    "    lines = result.stdout.split('\\n')[:15]  # Show first 15 tools\n",
    "    for line in lines:\n",
    "        if line.strip() and not line.startswith('_'):\n",
    "            print(line.strip())\n",
    "    \n",
    "    print(\"\\nSAGA is ready for geospatial analysis!\")\n",
    "    return True\n",
    "\n",
    "# Run demonstration\n",
    "demonstrate_saga()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f08a2e84-4237-4087-93a0-73aad735c247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ALL 73 libraries...\n",
      "Processing 1/73: climate_tools\n",
      "Processing 2/73: contrib_perego\n",
      "Processing 3/73: db_odbc\n",
      "Processing 4/73: db_pgsql\n",
      "Processing 5/73: docs_html\n",
      "Processing 6/73: docs_pdf\n",
      "Processing 7/73: garden_fractals\n",
      "Processing 8/73: garden_webservices\n",
      "Processing 9/73: grid_analysis\n",
      "Processing 10/73: grid_calculus\n",
      "Processing 11/73: grid_calculus_bsl\n",
      "Processing 12/73: grid_filter\n",
      "Processing 13/73: grid_gridding\n",
      "Processing 14/73: grid_spline\n",
      "Processing 15/73: grid_tools\n",
      "Processing 16/73: grid_visualisation\n",
      "Processing 17/73: grids_tools\n",
      "Processing 18/73: imagery_classification\n",
      "Processing 19/73: imagery_isocluster\n",
      "Processing 20/73: imagery_maxent\n",
      "Processing 21/73: imagery_opencv\n",
      "Processing 22/73: imagery_photogrammetry\n",
      "Processing 23/73: imagery_segmentation\n",
      "Processing 24/73: imagery_svm\n",
      "Processing 25/73: imagery_tools\n",
      "Processing 26/73: io_esri_e00\n",
      "Processing 27/73: io_gdal\n",
      "Processing 28/73: io_gps\n",
      "Processing 29/73: io_grid\n",
      "Processing 30/73: io_grid_image\n",
      "Processing 31/73: io_shapes\n",
      "Processing 32/73: io_table\n",
      "Processing 33/73: io_virtual\n",
      "Processing 34/73: io_webservices\n",
      "Processing 35/73: pj_georeference\n",
      "Processing 36/73: pj_geotrans\n",
      "Processing 37/73: pj_proj4\n",
      "Processing 38/73: pointcloud_tools\n",
      "Processing 39/73: shapes_grid\n",
      "Processing 40/73: shapes_lines\n",
      "Processing 41/73: shapes_points\n",
      "Processing 42/73: shapes_polygons\n",
      "Processing 43/73: shapes_tools\n",
      "Processing 44/73: shapes_transect\n",
      "Processing 45/73: sim_air_flow\n",
      "Processing 46/73: sim_cellular_automata\n",
      "Processing 47/73: sim_ecosystems_hugget\n",
      "Processing 48/73: sim_erosion\n",
      "Processing 49/73: sim_fire_spreading\n",
      "Processing 50/73: sim_geomorphology\n",
      "Processing 51/73: sim_hydrology\n",
      "Processing 52/73: sim_ihacres\n",
      "Processing 53/73: sim_landscape_evolution\n",
      "Processing 54/73: sim_qm_of_esp\n",
      "Processing 55/73: sim_rivflow\n",
      "Processing 56/73: statistics_grid\n",
      "Processing 57/73: statistics_kriging\n",
      "Processing 58/73: statistics_points\n",
      "Processing 59/73: statistics_regression\n",
      "Processing 60/73: ta_channels\n",
      "Processing 61/73: ta_cliffmetrics\n",
      "Processing 62/73: ta_compound\n",
      "Processing 63/73: ta_hydrology\n",
      "Processing 64/73: ta_lighting\n",
      "Processing 65/73: ta_morphometry\n",
      "Processing 66/73: ta_preprocessor\n",
      "Processing 67/73: ta_profiles\n",
      "Processing 68/73: ta_slope_stability\n",
      "Processing 69/73: table_calculus\n",
      "Processing 70/73: table_tools\n",
      "Processing 71/73: tin_tools\n",
      "Processing 72/73: vis_3d_viewer\n",
      "Processing 73/73: tta_tools\n",
      "Total: 733 algorithms\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import subprocess\n",
    "import csv\n",
    "\n",
    "def export_all_saga_algorithms_fixed():\n",
    "    \"\"\"Use the working method but process ALL libraries\"\"\"\n",
    "    \n",
    "    env = {\n",
    "        'LD_LIBRARY_PATH': '/opt/saga/lib:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/opt/conda/envs/pygile/lib',\n",
    "        'SAGA_MLB': '/opt/saga/lib/saga'\n",
    "    }\n",
    "    \n",
    "    # Get libraries (your working code)\n",
    "    result = subprocess.run([\"/opt/saga/bin/saga_cmd\"], \n",
    "                          capture_output=True, text=True, env=env)\n",
    "    \n",
    "    libraries = []\n",
    "    lines = result.stdout.split('\\n')\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.startswith(' - '):\n",
    "            lib_name = line[3:].strip()\n",
    "            if lib_name.endswith(' *'):\n",
    "                lib_name = lib_name[:-2]\n",
    "            if lib_name and not lib_name.startswith('_'):\n",
    "                libraries.append(lib_name)\n",
    "    \n",
    "    unique_libraries = list(dict.fromkeys(libraries))  # Remove duplicates\n",
    "    \n",
    "    print(f\"Processing ALL {len(unique_libraries)} libraries...\")\n",
    "    \n",
    "    algorithms_data = []\n",
    "    \n",
    "    # Process ALL libraries (not just first 15)\n",
    "    for i, lib in enumerate(unique_libraries):\n",
    "        print(f\"Processing {i+1}/{len(unique_libraries)}: {lib}\")\n",
    "        \n",
    "        # Your working parsing code\n",
    "        result = subprocess.run([\"/opt/saga/bin/saga_cmd\", lib], \n",
    "                              capture_output=True, text=True, env=env)\n",
    "        \n",
    "        lines = result.stdout.split('\\n')\n",
    "        for line in lines:\n",
    "            match = re.match(r'^\\s*\\[(\\d+)\\]\\s+(.+)', line)\n",
    "            if match:\n",
    "                tool_id = match.group(1)\n",
    "                tool_name = match.group(2).strip()\n",
    "                algorithms_data.append([lib, tool_id, tool_name])\n",
    "    \n",
    "    # Save CSV\n",
    "    with open('/workspace/saga_all_algorithms.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['Library', 'Tool_ID', 'Algorithm_Name'])\n",
    "        writer.writerows(algorithms_data)\n",
    "    \n",
    "    print(f\"Total: {len(algorithms_data)} algorithms\")\n",
    "    return len(algorithms_data)\n",
    "\n",
    "# Run this\n",
    "total = export_all_saga_algorithms_fixed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "080856ce-6b39-40de-9448-ba70907fe3bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Complete GRASS Algorithm Extraction ===\n",
      "Scanning all GRASS directories...\n",
      "Checking: /opt/grass/grass84/bin\n",
      "  Found 357 new modules\n",
      "Checking: /opt/grass/grass84/scripts\n",
      "  Found 143 new modules\n",
      "Checking: /opt/grass/bin\n",
      "  Found 0 new modules\n",
      "Checking: /opt/grass/grass84/etc/python/grass/script\n",
      "  Found 1 new modules\n",
      "Total GRASS algorithms extracted: 501\n",
      "GRASS algorithms exported: 501 modules\n",
      "CSV saved to: /workspace/grass_all_algorithms.csv\n",
      "\n",
      "Categories:\n",
      "  Database: 19\n",
      "  Display: 43\n",
      "  General: 43\n",
      "  Imagery: 51\n",
      "  PostScript: 1\n",
      "  Raster: 167\n",
      "  Temporal: 51\n",
      "  Vector: 126\n",
      "\n",
      "Locations:\n",
      "  /opt/grass/grass84/bin: 357\n",
      "  /opt/grass/grass84/etc/python/grass/script: 1\n",
      "  /opt/grass/grass84/scripts: 143\n",
      "\n",
      "Total GRASS modules catalogued: 501\n",
      "Complete CSV saved as: grass_all_algorithms.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Complete GRASS GIS algorithm extraction from all directories\n",
    "Reference: Neteler & Mitasova (2008) - Open Source GIS: A GRASS GIS Approach\n",
    "\"\"\"\n",
    "import subprocess\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def get_all_grass_modules():\n",
    "    # Complete GRASS module discovery from all directories\n",
    "    algorithms = []\n",
    "    \n",
    "    # Module prefixes for categorization\n",
    "    module_categories = {\n",
    "        'r.': 'Raster',\n",
    "        'v.': 'Vector', \n",
    "        'g.': 'General',\n",
    "        'i.': 'Imagery',\n",
    "        't.': 'Temporal',\n",
    "        'd.': 'Display',\n",
    "        'db.': 'Database',\n",
    "        'ps.': 'PostScript'\n",
    "    }\n",
    "    \n",
    "    # All possible GRASS directories\n",
    "    grass_directories = [\n",
    "        '/opt/grass/grass84/bin',      # Core compiled modules\n",
    "        '/opt/grass/grass84/scripts',  # Python scripts\n",
    "        '/opt/grass/bin',              # Main binaries\n",
    "        '/opt/grass/grass84/etc/python/grass/script',  # Python modules\n",
    "    ]\n",
    "    \n",
    "    print(\"Scanning all GRASS directories...\")\n",
    "    \n",
    "    for grass_dir in grass_directories:\n",
    "        if os.path.exists(grass_dir):\n",
    "            print(f\"Checking: {grass_dir}\")\n",
    "            try:\n",
    "                files = os.listdir(grass_dir)\n",
    "                found_modules = 0\n",
    "                \n",
    "                for filename in sorted(files):\n",
    "                    # Check if it's a GRASS module by prefix\n",
    "                    for prefix, category in module_categories.items():\n",
    "                        if filename.startswith(prefix):\n",
    "                            # Avoid duplicates\n",
    "                            if not any(alg['algorithm_id'] == filename for alg in algorithms):\n",
    "                                # Get basic description\n",
    "                                desc = get_module_description_direct(filename, grass_dir)\n",
    "                                algorithms.append({\n",
    "                                    'tool': 'GRASS',\n",
    "                                    'provider': 'GRASS',\n",
    "                                    'algorithm_id': filename,\n",
    "                                    'display_name': desc,\n",
    "                                    'group': category,\n",
    "                                    'location': grass_dir\n",
    "                                })\n",
    "                                found_modules += 1\n",
    "                            break\n",
    "                \n",
    "                print(f\"  Found {found_modules} new modules\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  Error accessing {grass_dir}: {e}\")\n",
    "        else:\n",
    "            print(f\"  Directory not found: {grass_dir}\")\n",
    "    \n",
    "    print(f\"Total GRASS algorithms extracted: {len(algorithms)}\")\n",
    "    return algorithms\n",
    "\n",
    "def get_module_description_direct(module_name, module_dir):\n",
    "    # Get module description from multiple possible locations\n",
    "    \n",
    "    # Try different execution paths\n",
    "    possible_paths = [\n",
    "        f'{module_dir}/{module_name}',\n",
    "        f'/opt/grass/bin/{module_name}',\n",
    "        f'/opt/grass/grass84/bin/{module_name}',\n",
    "        f'/opt/grass/grass84/scripts/{module_name}'\n",
    "    ]\n",
    "    \n",
    "    for exec_path in possible_paths:\n",
    "        if os.path.exists(exec_path):\n",
    "            try:\n",
    "                env = os.environ.copy()\n",
    "                env['GISBASE'] = '/opt/grass'\n",
    "                env['PATH'] = '/opt/grass/bin:/opt/grass/grass84/bin:' + env.get('PATH', '')\n",
    "                \n",
    "                # Try to get help from the module\n",
    "                result = subprocess.run([exec_path, '--help'], \n",
    "                                      capture_output=True, text=True, env=env, timeout=5)\n",
    "                \n",
    "                if result.returncode == 0 or result.stderr:\n",
    "                    # Parse help output for description\n",
    "                    output = result.stdout + result.stderr\n",
    "                    lines = output.split('\\n')\n",
    "                    \n",
    "                    for line in lines:\n",
    "                        line = line.strip()\n",
    "                        if 'Description:' in line:\n",
    "                            return line.split('Description:', 1)[1].strip()\n",
    "                        elif line and not line.startswith(('Usage:', 'Flags:', 'Parameters:', 'ERROR:', 'WARNING:')):\n",
    "                            if len(line) > 10 and not line.startswith(('-', 'GRASS', 'grass')):\n",
    "                                return line\n",
    "                \n",
    "            except Exception:\n",
    "                continue\n",
    "    \n",
    "    # Fallback: return module name\n",
    "    return module_name\n",
    "\n",
    "def export_all_grass_algorithms():\n",
    "    # Generate comprehensive GRASS algorithm inventory\n",
    "    print(\"=== Complete GRASS Algorithm Extraction ===\")\n",
    "    \n",
    "    algorithms = get_all_grass_modules()\n",
    "    \n",
    "    if algorithms:\n",
    "        # Write to CSV\n",
    "        csv_path = '/workspace/grass_all_algorithms.csv'\n",
    "        with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            fieldnames = ['tool', 'provider', 'algorithm_id', 'display_name', 'group', 'location']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(algorithms)\n",
    "        \n",
    "        print(f\"GRASS algorithms exported: {len(algorithms)} modules\")\n",
    "        print(f\"CSV saved to: {csv_path}\")\n",
    "        \n",
    "        # Category summary\n",
    "        categories = {}\n",
    "        for alg in algorithms:\n",
    "            cat = alg['group']\n",
    "            categories[cat] = categories.get(cat, 0) + 1\n",
    "        \n",
    "        print(\"\\nCategories:\")\n",
    "        for cat, count in sorted(categories.items()):\n",
    "            print(f\"  {cat}: {count}\")\n",
    "        \n",
    "        # Location summary\n",
    "        locations = {}\n",
    "        for alg in algorithms:\n",
    "            loc = alg['location']\n",
    "            locations[loc] = locations.get(loc, 0) + 1\n",
    "        \n",
    "        print(\"\\nLocations:\")\n",
    "        for loc, count in sorted(locations.items()):\n",
    "            print(f\"  {loc}: {count}\")\n",
    "    \n",
    "    return len(algorithms)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    total = export_all_grass_algorithms()\n",
    "    print(f\"\\nTotal GRASS modules catalogued: {total}\")\n",
    "    print(\"Complete CSV saved as: grass_all_algorithms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae9aaa19-2c34-4667-8279-504850f01e59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== WhiteboxTools Algorithm Extraction ===\n",
      "\n",
      " Found WhiteboxTools via PATH: /opt/conda/envs/pygile/bin/whitebox_tools\n",
      " List tools command: Found 460 algorithms\n",
      " Found WhiteboxTools via PATH: /opt/conda/envs/pygile/bin/whitebox_tools\n",
      " Help output: Found 1 algorithms\n",
      " Python bindings (tool_help): Found 1377 algorithms\n",
      " Found WhiteboxTools via PATH: /opt/conda/envs/pygile/bin/whitebox_tools\n",
      " JSON output: No algorithms found\n",
      " Found WhiteboxTools via PATH: /opt/conda/envs/pygile/bin/whitebox_tools\n",
      " Found WhiteboxTools via PATH: /opt/conda/envs/pygile/bin/whitebox_tools\n",
      " List tools command: Found 460 algorithms\n",
      "Getting detailed help for 460 tools...\n",
      "  Progress: 1/460\n",
      "  Progress: 21/460\n",
      "  Progress: 41/460\n",
      "  Progress: 61/460\n",
      "  Progress: 81/460\n",
      "  Progress: 101/460\n",
      "  Progress: 121/460\n",
      "  Progress: 141/460\n",
      "  Progress: 161/460\n",
      "  Progress: 181/460\n",
      "  Progress: 201/460\n",
      "  Progress: 221/460\n",
      "  Progress: 241/460\n",
      "  Progress: 261/460\n",
      "  Progress: 281/460\n",
      "  Progress: 301/460\n",
      "  Progress: 321/460\n",
      "  Progress: 341/460\n",
      "  Progress: 361/460\n",
      "  Progress: 381/460\n",
      "  Progress: 401/460\n",
      "  Progress: 421/460\n",
      "  Progress: 441/460\n",
      " Individual help: Found 460 algorithms\n",
      "\n",
      "=== Results ===\n",
      " Total algorithms found: 464\n",
      " CSV saved to: /workspace/whitebox_algorithms.csv\n",
      "\n",
      "Categories:\n",
      "  General: 168\n",
      "  Vector Analysis: 64\n",
      "  Image Processing: 46\n",
      "  Terrain Analysis: 45\n",
      "  Hydrological Analysis: 37\n",
      "  LiDAR Processing: 26\n",
      "  Mathematical Analysis: 24\n",
      "  Raster Processing: 23\n",
      "  Preprocessing: 14\n",
      "  Classification: 5\n",
      "  Geomorphometry: 5\n",
      "  Change Detection: 4\n",
      "  Input/Output: 3\n",
      "\n",
      "Detection methods:\n",
      "  help_output: 1\n",
      "  individual_help: 460\n",
      "  listtools_command: 460\n",
      "  python_bindings: 3\n",
      "\n",
      "Final count: 464 WhiteboxTools algorithms catalogued\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "WhiteboxTools algorithm extraction using multiple detection methods\n",
    "Reference: WhiteboxTools documentation and CLI interface\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "\n",
    "def find_whitebox_executable():\n",
    "    \"\"\"Find WhiteboxTools executable in common locations\"\"\"\n",
    "    \n",
    "    # Common installation paths\n",
    "    possible_paths = [\n",
    "        '/usr/local/bin/whitebox_tools',\n",
    "        '/usr/bin/whitebox_tools',\n",
    "        '/opt/WhiteboxTools/whitebox_tools',\n",
    "        '/opt/whitebox/whitebox_tools',\n",
    "        './whitebox_tools',\n",
    "        'whitebox_tools',\n",
    "        '/usr/local/bin/whiteboxtools',\n",
    "        '/usr/bin/whiteboxtools',\n",
    "        'whiteboxtools'\n",
    "    ]\n",
    "    \n",
    "    # Check PATH first\n",
    "    try:\n",
    "        result = subprocess.run(['which', 'whitebox_tools'], capture_output=True, text=True)\n",
    "        if result.returncode == 0 and result.stdout.strip():\n",
    "            path = result.stdout.strip()\n",
    "            print(f\" Found WhiteboxTools via PATH: {path}\")\n",
    "            return path\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Check alternative name\n",
    "    try:\n",
    "        result = subprocess.run(['which', 'whiteboxtools'], capture_output=True, text=True)\n",
    "        if result.returncode == 0 and result.stdout.strip():\n",
    "            path = result.stdout.strip()\n",
    "            print(f\" Found WhiteboxTools via PATH: {path}\")\n",
    "            return path\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Check specific paths\n",
    "    for path in possible_paths:\n",
    "        if os.path.isfile(path) and os.access(path, os.X_OK):\n",
    "            print(f\" Found WhiteboxTools at: {path}\")\n",
    "            return path\n",
    "    \n",
    "    print(\" WhiteboxTools executable not found\")\n",
    "    return None\n",
    "\n",
    "def get_whitebox_tools_list():\n",
    "    \"\"\"Get all WhiteboxTools using the --listtools flag\"\"\"\n",
    "    algorithms = []\n",
    "    \n",
    "    wb_exec = find_whitebox_executable()\n",
    "    if not wb_exec:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # Run whitebox_tools --listtools\n",
    "        result = subprocess.run([wb_exec, '--listtools'], \n",
    "                              capture_output=True, \n",
    "                              text=True, \n",
    "                              timeout=30)\n",
    "        \n",
    "        if result.returncode == 0 and result.stdout:\n",
    "            output = result.stdout\n",
    "            \n",
    "            # Parse the tool list output\n",
    "            lines = output.split('\\n')\n",
    "            \n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                \n",
    "                # Skip empty lines and headers\n",
    "                if not line or line.startswith('Available') or line.startswith('='):\n",
    "                    continue\n",
    "                \n",
    "                # Parse tool entries (format varies)\n",
    "                # Common formats:\n",
    "                # \"ToolName: Description\"\n",
    "                # \"ToolName - Description\"\n",
    "                # \"ToolName Description\"\n",
    "                \n",
    "                tool_name = \"\"\n",
    "                description = \"\"\n",
    "                \n",
    "                if ':' in line:\n",
    "                    parts = line.split(':', 1)\n",
    "                    tool_name = parts[0].strip()\n",
    "                    description = parts[1].strip() if len(parts) > 1 else tool_name\n",
    "                elif ' - ' in line:\n",
    "                    parts = line.split(' - ', 1)\n",
    "                    tool_name = parts[0].strip()\n",
    "                    description = parts[1].strip() if len(parts) > 1 else tool_name\n",
    "                elif line and not line.startswith(' '):\n",
    "                    # Single word tool name\n",
    "                    tool_name = line.split()[0]\n",
    "                    description = line\n",
    "                \n",
    "                if tool_name and len(tool_name) > 1:\n",
    "                    algorithms.append({\n",
    "                        'tool': 'WhiteboxTools',\n",
    "                        'provider': 'WhiteboxTools',\n",
    "                        'algorithm_id': tool_name,\n",
    "                        'display_name': description,\n",
    "                        'group': categorize_whitebox_tool(tool_name),\n",
    "                        'detection_method': 'listtools_command'\n",
    "                    })\n",
    "            \n",
    "            print(f\" List tools command: Found {len(algorithms)} algorithms\")\n",
    "        else:\n",
    "            print(f\" List tools command failed: {result.stderr[:100]}...\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\" List tools command failed: {str(e)[:50]}...\")\n",
    "    \n",
    "    return algorithms\n",
    "\n",
    "def get_whitebox_help_output():\n",
    "    \"\"\"Get WhiteboxTools using the help output\"\"\"\n",
    "    algorithms = []\n",
    "    \n",
    "    wb_exec = find_whitebox_executable()\n",
    "    if not wb_exec:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # Run whitebox_tools --help or just whitebox_tools\n",
    "        for cmd_args in [['--help'], ['-h'], []]:\n",
    "            try:\n",
    "                result = subprocess.run([wb_exec] + cmd_args, \n",
    "                                      capture_output=True, \n",
    "                                      text=True, \n",
    "                                      timeout=10)\n",
    "                \n",
    "                output = result.stdout + result.stderr\n",
    "                \n",
    "                if output and ('tools' in output.lower() or 'available' in output.lower()):\n",
    "                    # Parse help output for tool names\n",
    "                    lines = output.split('\\n')\n",
    "                    \n",
    "                    in_tools_section = False\n",
    "                    \n",
    "                    for line in lines:\n",
    "                        line = line.strip()\n",
    "                        \n",
    "                        # Detect tools section\n",
    "                        if any(keyword in line.lower() for keyword in ['available tools', 'tool list', 'supported tools']):\n",
    "                            in_tools_section = True\n",
    "                            continue\n",
    "                        \n",
    "                        if in_tools_section and line:\n",
    "                            # Extract tool names from help output\n",
    "                            if line.startswith('-') or line.startswith('*'):\n",
    "                                continue\n",
    "                            \n",
    "                            # Look for tool name patterns\n",
    "                            tool_match = re.match(r'^([a-zA-Z][a-zA-Z0-9_]*)', line)\n",
    "                            if tool_match:\n",
    "                                tool_name = tool_match.group(1)\n",
    "                                if len(tool_name) > 2:\n",
    "                                    algorithms.append({\n",
    "                                        'tool': 'WhiteboxTools',\n",
    "                                        'provider': 'WhiteboxTools',\n",
    "                                        'algorithm_id': tool_name,\n",
    "                                        'display_name': line,\n",
    "                                        'group': categorize_whitebox_tool(tool_name),\n",
    "                                        'detection_method': 'help_output'\n",
    "                                    })\n",
    "                    \n",
    "                    if algorithms:\n",
    "                        print(f\" Help output: Found {len(algorithms)} algorithms\")\n",
    "                        break\n",
    "                        \n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\" Help output method failed: {str(e)[:50]}...\")\n",
    "    \n",
    "    if not algorithms:\n",
    "        print(\" Help output: No algorithms found\")\n",
    "    \n",
    "    return algorithms\n",
    "\n",
    "def get_whitebox_python_bindings():\n",
    "    \"\"\"Try to get WhiteboxTools via Python whitebox package\"\"\"\n",
    "    algorithms = []\n",
    "    \n",
    "    try:\n",
    "        # Try to import whitebox package\n",
    "        import whitebox\n",
    "        \n",
    "        # Check if whitebox has tool listing capabilities\n",
    "        wbt = whitebox.WhiteboxTools()\n",
    "        \n",
    "        # Try different methods to get tool list\n",
    "        methods_to_try = [\n",
    "            ('list_tools', lambda: wbt.list_tools()),\n",
    "            ('tool_help', lambda: wbt.tool_help()),\n",
    "            ('help', lambda: wbt.help())\n",
    "        ]\n",
    "        \n",
    "        for method_name, method_func in methods_to_try:\n",
    "            try:\n",
    "                result = method_func()\n",
    "                \n",
    "                if result and isinstance(result, str):\n",
    "                    # Parse tool names from the result\n",
    "                    lines = result.split('\\n')\n",
    "                    \n",
    "                    for line in lines:\n",
    "                        line = line.strip()\n",
    "                        \n",
    "                        # Look for tool patterns in Python output\n",
    "                        if ':' in line:\n",
    "                            tool_name = line.split(':')[0].strip()\n",
    "                            description = line.split(':', 1)[1].strip()\n",
    "                            \n",
    "                            if len(tool_name) > 2 and tool_name.replace('_', '').isalnum():\n",
    "                                algorithms.append({\n",
    "                                    'tool': 'WhiteboxTools',\n",
    "                                    'provider': 'WhiteboxTools',\n",
    "                                    'algorithm_id': tool_name,\n",
    "                                    'display_name': description,\n",
    "                                    'group': categorize_whitebox_tool(tool_name),\n",
    "                                    'detection_method': 'python_bindings'\n",
    "                                })\n",
    "                \n",
    "                if algorithms:\n",
    "                    print(f\" Python bindings ({method_name}): Found {len(algorithms)} algorithms\")\n",
    "                    break\n",
    "                    \n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if not algorithms:\n",
    "            print(\" Python bindings: No algorithms found\")\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\" Python bindings: whitebox package not available\")\n",
    "    except Exception as e:\n",
    "        print(f\" Python bindings failed: {str(e)[:50]}...\")\n",
    "    \n",
    "    return algorithms\n",
    "\n",
    "def get_whitebox_individual_tools():\n",
    "    \"\"\"Get individual tool help to extract more details\"\"\"\n",
    "    algorithms = []\n",
    "    \n",
    "    wb_exec = find_whitebox_executable()\n",
    "    if not wb_exec:\n",
    "        return []\n",
    "    \n",
    "    # First get a basic list of tools\n",
    "    base_tools = get_whitebox_tools_list()\n",
    "    \n",
    "    if not base_tools:\n",
    "        # Try to discover some common tools\n",
    "        common_tools = [\n",
    "            'slope', 'aspect', 'hillshade', 'contours', 'watershed',\n",
    "            'flow_direction', 'flow_accumulation', 'stream_network',\n",
    "            'fill_depressions', 'breach_depressions', 'gaussian_filter',\n",
    "            'median_filter', 'buffer', 'clip', 'reclass', 'mosaic'\n",
    "        ]\n",
    "        \n",
    "        base_tools = [{'algorithm_id': tool} for tool in common_tools]\n",
    "    \n",
    "    print(f\"Getting detailed help for {len(base_tools)} tools...\")\n",
    "    \n",
    "    for i, tool_info in enumerate(base_tools):\n",
    "        tool_name = tool_info['algorithm_id']\n",
    "        \n",
    "        if i % 20 == 0:  # Progress indicator\n",
    "            print(f\"  Progress: {i+1}/{len(base_tools)}\")\n",
    "        \n",
    "        try:\n",
    "            # Get help for individual tool\n",
    "            result = subprocess.run([wb_exec, f'--run={tool_name}', '--help'], \n",
    "                                  capture_output=True, \n",
    "                                  text=True, \n",
    "                                  timeout=5)\n",
    "            \n",
    "            if result.returncode != 0:\n",
    "                # Try alternative help format\n",
    "                result = subprocess.run([wb_exec, '--tool=' + tool_name], \n",
    "                                      capture_output=True, \n",
    "                                      text=True, \n",
    "                                      timeout=5)\n",
    "            \n",
    "            output = result.stdout + result.stderr\n",
    "            description = tool_name\n",
    "            \n",
    "            if output:\n",
    "                # Extract description from tool help\n",
    "                desc_patterns = [\n",
    "                    r'Description:\\s*(.+?)(?:\\n\\n|\\nUsage:|\\nParameters:)',\n",
    "                    r'DESCRIPTION:\\s*(.+?)(?:\\n\\n|\\nUSAGE:|\\nPARAMETERS:)',\n",
    "                    r'Purpose:\\s*(.+?)(?:\\n)',\n",
    "                    r'Brief:\\s*(.+?)(?:\\n)',\n",
    "                    r'Summary:\\s*(.+?)(?:\\n)'\n",
    "                ]\n",
    "                \n",
    "                for pattern in desc_patterns:\n",
    "                    match = re.search(pattern, output, re.DOTALL | re.IGNORECASE)\n",
    "                    if match:\n",
    "                        desc = match.group(1).strip()\n",
    "                        if len(desc) > len(description) and len(desc) < 200:\n",
    "                            description = desc\n",
    "                            break\n",
    "                \n",
    "                # Clean up description\n",
    "                description = ' '.join(description.split())\n",
    "            \n",
    "            algorithms.append({\n",
    "                'tool': 'WhiteboxTools',\n",
    "                'provider': 'WhiteboxTools',\n",
    "                'algorithm_id': tool_name,\n",
    "                'display_name': description,\n",
    "                'group': categorize_whitebox_tool(tool_name),\n",
    "                'detection_method': 'individual_help'\n",
    "            })\n",
    "            \n",
    "        except:\n",
    "            # Add basic entry if help fails\n",
    "            algorithms.append({\n",
    "                'tool': 'WhiteboxTools',\n",
    "                'provider': 'WhiteboxTools',\n",
    "                'algorithm_id': tool_name,\n",
    "                'display_name': tool_name,\n",
    "                'group': categorize_whitebox_tool(tool_name),\n",
    "                'detection_method': 'individual_help'\n",
    "            })\n",
    "    \n",
    "    print(f\" Individual help: Found {len(algorithms)} algorithms\")\n",
    "    return algorithms\n",
    "\n",
    "def get_whitebox_json_output():\n",
    "    \"\"\"Try to get tool list in JSON format if supported\"\"\"\n",
    "    algorithms = []\n",
    "    \n",
    "    wb_exec = find_whitebox_executable()\n",
    "    if not wb_exec:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # Try JSON output formats\n",
    "        json_commands = [\n",
    "            ['--listtools', '--json'],\n",
    "            ['--list', '--json'],\n",
    "            ['--tools', '--json']\n",
    "        ]\n",
    "        \n",
    "        for cmd_args in json_commands:\n",
    "            try:\n",
    "                result = subprocess.run([wb_exec] + cmd_args, \n",
    "                                      capture_output=True, \n",
    "                                      text=True, \n",
    "                                      timeout=10)\n",
    "                \n",
    "                if result.returncode == 0 and result.stdout:\n",
    "                    try:\n",
    "                        data = json.loads(result.stdout)\n",
    "                        \n",
    "                        # Parse JSON structure (format may vary)\n",
    "                        if isinstance(data, dict):\n",
    "                            if 'tools' in data:\n",
    "                                tools = data['tools']\n",
    "                            elif 'available_tools' in data:\n",
    "                                tools = data['available_tools']\n",
    "                            else:\n",
    "                                tools = data\n",
    "                        elif isinstance(data, list):\n",
    "                            tools = data\n",
    "                        else:\n",
    "                            continue\n",
    "                        \n",
    "                        for tool_info in tools:\n",
    "                            if isinstance(tool_info, dict):\n",
    "                                tool_name = tool_info.get('name', tool_info.get('tool', ''))\n",
    "                                description = tool_info.get('description', tool_info.get('desc', tool_name))\n",
    "                            elif isinstance(tool_info, str):\n",
    "                                tool_name = tool_info\n",
    "                                description = tool_info\n",
    "                            else:\n",
    "                                continue\n",
    "                            \n",
    "                            if tool_name and len(tool_name) > 1:\n",
    "                                algorithms.append({\n",
    "                                    'tool': 'WhiteboxTools',\n",
    "                                    'provider': 'WhiteboxTools',\n",
    "                                    'algorithm_id': tool_name,\n",
    "                                    'display_name': description,\n",
    "                                    'group': categorize_whitebox_tool(tool_name),\n",
    "                                    'detection_method': 'json_output'\n",
    "                                })\n",
    "                        \n",
    "                        if algorithms:\n",
    "                            print(f\" JSON output: Found {len(algorithms)} algorithms\")\n",
    "                            break\n",
    "                            \n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "                        \n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\" JSON output method failed: {str(e)[:50]}...\")\n",
    "    \n",
    "    if not algorithms:\n",
    "        print(\" JSON output: No algorithms found\")\n",
    "    \n",
    "    return algorithms\n",
    "\n",
    "def categorize_whitebox_tool(tool_name):\n",
    "    \"\"\"Categorize WhiteboxTools based on tool name\"\"\"\n",
    "    \n",
    "    tool_name_lower = tool_name.lower()\n",
    "    \n",
    "    # Terrain analysis\n",
    "    if any(keyword in tool_name_lower for keyword in ['slope', 'aspect', 'hillshade', 'curvature', 'elevation', 'terrain', 'topographic', 'ruggedness']):\n",
    "        return 'Terrain Analysis'\n",
    "    \n",
    "    # Hydrology\n",
    "    elif any(keyword in tool_name_lower for keyword in ['flow', 'watershed', 'stream', 'drainage', 'accumulation', 'direction', 'basin', 'pour', 'outlet', 'hydro']):\n",
    "        return 'Hydrological Analysis'\n",
    "    \n",
    "    # Image processing and filtering\n",
    "    elif any(keyword in tool_name_lower for keyword in ['filter', 'smooth', 'gaussian', 'median', 'bilateral', 'edge', 'enhance', 'sharpen', 'blur']):\n",
    "        return 'Image Processing'\n",
    "    \n",
    "    # Geomorphometry\n",
    "    elif any(keyword in tool_name_lower for keyword in ['geomorphon', 'landform', 'relative', 'position', 'morphometry', 'relief']):\n",
    "        return 'Geomorphometry'\n",
    "    \n",
    "    # Vector tools\n",
    "    elif any(keyword in tool_name_lower for keyword in ['vector', 'polygon', 'line', 'point', 'buffer', 'clip', 'overlay', 'intersection', 'union']):\n",
    "        return 'Vector Analysis'\n",
    "    \n",
    "    # Raster operations\n",
    "    elif any(keyword in tool_name_lower for keyword in ['raster', 'grid', 'resample', 'reproject', 'mosaic', 'merge', 'clip', 'extract']):\n",
    "        return 'Raster Processing'\n",
    "    \n",
    "    # Classification and clustering\n",
    "    elif any(keyword in tool_name_lower for keyword in ['classify', 'cluster', 'kmeans', 'isodata', 'segment', 'region']):\n",
    "        return 'Classification'\n",
    "    \n",
    "    # Mathematical operations\n",
    "    elif any(keyword in tool_name_lower for keyword in ['math', 'calculator', 'statistics', 'zonal', 'histogram', 'sum', 'mean', 'max', 'min']):\n",
    "        return 'Mathematical Analysis'\n",
    "    \n",
    "    # LiDAR processing\n",
    "    elif any(keyword in tool_name_lower for keyword in ['lidar', 'las', 'point_cloud', 'dtm', 'dsm', 'canopy', 'height']):\n",
    "        return 'LiDAR Processing'\n",
    "    \n",
    "    # Input/Output\n",
    "    elif any(keyword in tool_name_lower for keyword in ['import', 'export', 'convert', 'read', 'write', 'format', 'ascii']):\n",
    "        return 'Input/Output'\n",
    "    \n",
    "    # Preprocessing\n",
    "    elif any(keyword in tool_name_lower for keyword in ['fill', 'breach', 'depression', 'sink', 'correct', 'preprocess']):\n",
    "        return 'Preprocessing'\n",
    "    \n",
    "    # Change detection\n",
    "    elif any(keyword in tool_name_lower for keyword in ['change', 'difference', 'delta', 'temporal', 'time']):\n",
    "        return 'Change Detection'\n",
    "    \n",
    "    else:\n",
    "        return 'General'\n",
    "\n",
    "def merge_algorithms(algorithm_lists):\n",
    "    \"\"\"Merge algorithm lists and remove duplicates\"\"\"\n",
    "    seen = {}\n",
    "    merged = []\n",
    "    \n",
    "    for alg_list in algorithm_lists:\n",
    "        for alg in alg_list:\n",
    "            alg_id = alg['algorithm_id']\n",
    "            \n",
    "            if alg_id not in seen:\n",
    "                seen[alg_id] = alg\n",
    "                merged.append(alg)\n",
    "            else:\n",
    "                # Update existing entry with better description and additional detection method\n",
    "                existing = seen[alg_id]\n",
    "                \n",
    "                # Use longer, more descriptive display name\n",
    "                if len(alg['display_name']) > len(existing['display_name']):\n",
    "                    existing['display_name'] = alg['display_name']\n",
    "                \n",
    "                # Combine detection methods\n",
    "                if alg['detection_method'] not in existing['detection_method']:\n",
    "                    existing['detection_method'] += f\", {alg['detection_method']}\"\n",
    "    \n",
    "    return merged\n",
    "\n",
    "def export_whitebox_algorithms():\n",
    "    \"\"\"Export all WhiteboxTools algorithms to CSV\"\"\"\n",
    "    \n",
    "    print(\"=== WhiteboxTools Algorithm Extraction ===\\n\")\n",
    "    \n",
    "    # Detection methods\n",
    "    detection_methods = [\n",
    "        (\"List Tools Command\", get_whitebox_tools_list),\n",
    "        (\"Help Output\", get_whitebox_help_output),\n",
    "        (\"Python Bindings\", get_whitebox_python_bindings),\n",
    "        (\"JSON Output\", get_whitebox_json_output),\n",
    "        (\"Individual Help\", get_whitebox_individual_tools)\n",
    "    ]\n",
    "    \n",
    "    all_algorithms = []\n",
    "    \n",
    "    for method_name, method_func in detection_methods:\n",
    "        try:\n",
    "            algorithms = method_func()\n",
    "            if algorithms:\n",
    "                all_algorithms.append(algorithms)\n",
    "        except Exception as e:\n",
    "            print(f\" {method_name}: Failed ({str(e)[:50]}...)\")\n",
    "    \n",
    "    # Merge all results\n",
    "    if all_algorithms:\n",
    "        merged_algorithms = merge_algorithms(all_algorithms)\n",
    "        \n",
    "        # Write to CSV\n",
    "        csv_path = '/workspace/whitebox_algorithms.csv'\n",
    "        with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            fieldnames = ['tool', 'provider', 'algorithm_id', 'display_name', 'group', 'detection_method']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(merged_algorithms)\n",
    "        \n",
    "        print(f\"\\n=== Results ===\")\n",
    "        print(f\" Total algorithms found: {len(merged_algorithms)}\")\n",
    "        print(f\" CSV saved to: {csv_path}\")\n",
    "        \n",
    "        # Category summary\n",
    "        categories = {}\n",
    "        for alg in merged_algorithms:\n",
    "            cat = alg['group']\n",
    "            categories[cat] = categories.get(cat, 0) + 1\n",
    "        \n",
    "        print(f\"\\nCategories:\")\n",
    "        sorted_cats = sorted(categories.items(), key=lambda x: x[1], reverse=True)\n",
    "        for cat, count in sorted_cats:\n",
    "            print(f\"  {cat}: {count}\")\n",
    "        \n",
    "        # Detection method summary\n",
    "        detection_stats = {}\n",
    "        for alg in merged_algorithms:\n",
    "            methods = [m.strip() for m in alg['detection_method'].split(',')]\n",
    "            for method in methods:\n",
    "                detection_stats[method] = detection_stats.get(method, 0) + 1\n",
    "        \n",
    "        print(f\"\\nDetection methods:\")\n",
    "        for method, count in sorted(detection_stats.items()):\n",
    "            print(f\"  {method}: {count}\")\n",
    "        \n",
    "        return len(merged_algorithms)\n",
    "    else:\n",
    "        print(\" No WhiteboxTools algorithms found\")\n",
    "        return 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    total = export_whitebox_algorithms()\n",
    "    print(f\"\\nFinal count: {total} WhiteboxTools algorithms catalogued\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c71ff0b-be93-44dc-8e9f-59414a8443cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Python Geospatial Libraries Algorithm Extraction ===\n",
      "\n",
      "\n",
      "--- Processing GDAL/OGR ---\n",
      " osgeo.gdal: Found 620 functions\n",
      " osgeo.ogr: Found 518 functions\n",
      " osgeo.osr: Found 187 functions\n",
      " osgeo.gdal_array: Found 32 functions\n",
      " osgeo.gdalconst: Found 0 functions\n",
      " GDAL/OGR: Total 1357 functions extracted\n",
      "\n",
      "--- Processing Rasterio ---\n",
      " rasterio: Found 131 functions\n",
      " rasterio.features: Found 103 functions\n",
      " rasterio.mask: Found 5 functions\n",
      " rasterio.merge: Found 71 functions\n",
      " rasterio.plot: Found 50 functions\n",
      " rasterio.sample: Found 14 functions\n",
      " rasterio.transform: Found 51 functions\n",
      " rasterio.warp: Found 39 functions\n",
      " rasterio.windows: Found 47 functions\n",
      " rasterio.enums: Found 0 functions\n",
      " rasterio.crs: Found 30 functions\n",
      " Rasterio: Total 541 functions extracted\n",
      "\n",
      "--- Processing Shapely ---\n",
      " shapely.geometry: Found 280 functions\n",
      " shapely.ops: Found 266 functions\n",
      " shapely.affinity: Found 6 functions\n",
      " shapely.algorithms: Found 0 functions\n",
      " shapely.predicates: Found 32 functions\n",
      " shapely.validation: Found 2 functions\n",
      " shapely.prepared: Found 11 functions\n",
      " Shapely: Total 597 functions extracted\n",
      "\n",
      "--- Processing GeoPandas ---\n",
      " geopandas: Found 570 functions\n",
      " geopandas.tools: Found 7 functions\n",
      " geopandas.datasets: Found 1 functions\n",
      " GeoPandas: Total 578 functions extracted\n",
      "\n",
      "--- Processing Scikit-image ---\n",
      " skimage.filters: Found 46 functions\n",
      " skimage.morphology: Found 50 functions\n",
      " skimage.segmentation: Found 20 functions\n",
      " skimage.feature: Found 45 functions\n",
      " skimage.transform: Found 46 functions\n",
      " skimage.restoration: Found 17 functions\n",
      " skimage.exposure: Found 10 functions\n",
      " skimage.measure: Found 42 functions\n",
      " skimage.color: Found 41 functions\n",
      " skimage.util: Found 23 functions\n",
      " Scikit-image: Total 340 functions extracted\n",
      "\n",
      "--- Processing OpenCV ---\n",
      " cv2: Found 4540 functions\n",
      " OpenCV: Total 4540 functions extracted\n",
      "\n",
      "--- Processing SciPy ---\n",
      " scipy.ndimage: Found 74 functions\n",
      " scipy.spatial: Found 43 functions\n",
      " scipy.interpolate: Found 182 functions\n",
      " scipy.signal: Found 183 functions\n",
      " scipy.stats: Found 299 functions\n",
      " SciPy: Total 781 functions extracted\n",
      "\n",
      "--- Processing NumPy ---\n",
      " numpy: Found 3900 functions\n",
      " numpy.ma: Found 434 functions\n",
      " numpy.linalg: Found 1 functions\n",
      " NumPy: Total 4335 functions extracted\n",
      "\n",
      "--- Processing Other GIS Libraries ---\n",
      " fiona: Found 146 functions\n",
      " pyproj: Found 70 functions\n",
      " cartopy: Found 50 functions\n",
      " folium: Found 508 functions\n",
      " xarray: Found 634 functions\n",
      " rioxarray: Not available\n",
      " geopy: Found 72 functions\n",
      " contextily: Found 12 functions\n",
      " earthpy: Found 2 functions\n",
      " rasterstats: Not available\n",
      " geoplot: Found 40 functions\n",
      " plotly.express: Found 43 functions\n",
      " Other GIS Libraries: Total 1577 functions extracted\n",
      "\n",
      "=== Results ===\n",
      " Total algorithms found: 14646\n",
      " CSV saved to: /workspace/python_gis_algorithms.csv\n",
      "\n",
      "Top providers:\n",
      "  cv2: 4540\n",
      "  numpy: 3900\n",
      "  xarray: 634\n",
      "  gdal.gdal: 620\n",
      "  geopandas: 570\n",
      "  gdal.ogr: 518\n",
      "  folium: 508\n",
      "  numpy.ma: 434\n",
      "  scipy.stats: 299\n",
      "  shapely.geometry: 280\n",
      "\n",
      "Top categories:\n",
      "  OpenCV General: 4324\n",
      "  NumPy General: 3168\n",
      "  GDAL General: 1086\n",
      "  General: 737\n",
      "  NumPy Math: 646\n",
      "  GeoPandas General: 511\n",
      "  Folium Tools: 508\n",
      "  Rasterio General: 370\n",
      "  NumPy Masked Arrays: 366\n",
      "  Shapely Operations: 306\n",
      "  SciPy Statistics: 299\n",
      "  Shapely General: 244\n",
      "  SciPy Signal Processing: 183\n",
      "  SciPy Interpolation: 182\n",
      "  GDAL I/O: 170\n",
      "\n",
      "Final count: 14646 Python geospatial algorithms catalogued\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Python geospatial libraries algorithm extraction\n",
    "Extracts functions/algorithms from major Python GIS and remote sensing libraries\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "import importlib\n",
    "import warnings\n",
    "import pkgutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Nuclear option - suppress everything\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Try to suppress IPython/Jupyter warnings\n",
    "try:\n",
    "    from IPython.core.interactiveshell import InteractiveShell\n",
    "    InteractiveShell.showtraceback = lambda self, exc_tuple=None, filename=None, tb_offset=None, exception_only=False, running_compiled_code=False: None\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Redirect file descriptors at OS level\n",
    "import contextlib\n",
    "@contextlib.contextmanager\n",
    "def suppress_fd_output():\n",
    "    \"\"\"Suppress output by redirecting file descriptors\"\"\"\n",
    "    with open(os.devnull, 'w') as devnull:\n",
    "        old_stdout = os.dup(1)\n",
    "        old_stderr = os.dup(2)\n",
    "        try:\n",
    "            os.dup2(devnull.fileno(), 1)\n",
    "            os.dup2(devnull.fileno(), 2)\n",
    "            yield\n",
    "        finally:\n",
    "            os.dup2(old_stdout, 1)\n",
    "            os.dup2(old_stderr, 2)\n",
    "            os.close(old_stdout)\n",
    "            os.close(old_stderr)\n",
    "\n",
    "def safe_import(module_name):\n",
    "    \"\"\"Safely import a module and return it, or None if import fails\"\"\"\n",
    "    try:\n",
    "        with suppress_fd_output():\n",
    "            return importlib.import_module(module_name)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_module_functions(module, module_name, exclude_private=True, exclude_classes=False):\n",
    "    \"\"\"Extract functions from a module\"\"\"\n",
    "    functions = []\n",
    "    \n",
    "    if not module:\n",
    "        return functions\n",
    "    \n",
    "    try:\n",
    "        with suppress_fd_output():\n",
    "            for name in dir(module):\n",
    "                if exclude_private and name.startswith('_'):\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    obj = getattr(module, name)\n",
    "                    \n",
    "                    # Check if it's a function or method\n",
    "                    if inspect.isfunction(obj) or inspect.ismethod(obj):\n",
    "                        # Get function signature and docstring\n",
    "                        try:\n",
    "                            sig = str(inspect.signature(obj))\n",
    "                        except:\n",
    "                            sig = \"\"\n",
    "                        \n",
    "                        try:\n",
    "                            doc = inspect.getdoc(obj) or \"\"\n",
    "                            # Take first line of docstring as description\n",
    "                            description = doc.split('\\n')[0] if doc else name\n",
    "                            if len(description) > 200:\n",
    "                                description = description[:200] + \"...\"\n",
    "                        except:\n",
    "                            description = name\n",
    "                        \n",
    "                        functions.append({\n",
    "                            'tool': 'Python',\n",
    "                            'provider': module_name,\n",
    "                            'algorithm_id': f\"{module_name}.{name}\",\n",
    "                            'display_name': description,\n",
    "                            'group': categorize_python_function(module_name, name),\n",
    "                            'detection_method': 'introspection'\n",
    "                        })\n",
    "                    \n",
    "                    # Optionally include classes with callable methods\n",
    "                    elif not exclude_classes and inspect.isclass(obj):\n",
    "                        try:\n",
    "                            # Get class methods that are likely algorithms\n",
    "                            for method_name in dir(obj):\n",
    "                                if not method_name.startswith('_'):\n",
    "                                    method_obj = getattr(obj, method_name)\n",
    "                                    if callable(method_obj):\n",
    "                                        try:\n",
    "                                            doc = inspect.getdoc(method_obj) or \"\"\n",
    "                                            description = doc.split('\\n')[0] if doc else f\"{name}.{method_name}\"\n",
    "                                            if len(description) > 200:\n",
    "                                                description = description[:200] + \"...\"\n",
    "                                        except:\n",
    "                                            description = f\"{name}.{method_name}\"\n",
    "                                        \n",
    "                                        functions.append({\n",
    "                                            'tool': 'Python',\n",
    "                                            'provider': module_name,\n",
    "                                            'algorithm_id': f\"{module_name}.{name}.{method_name}\",\n",
    "                                            'display_name': description,\n",
    "                                            'group': categorize_python_function(module_name, method_name),\n",
    "                                            'detection_method': 'class_methods'\n",
    "                                        })\n",
    "                        except:\n",
    "                            continue\n",
    "                            \n",
    "                except:\n",
    "                    continue\n",
    "                    \n",
    "    except Exception as e:\n",
    "        pass  # Silently skip problematic modules\n",
    "    \n",
    "    return functions\n",
    "\n",
    "def get_submodule_functions(module, module_name, max_depth=2, current_depth=0):\n",
    "    \"\"\"Recursively get functions from submodules\"\"\"\n",
    "    functions = []\n",
    "    \n",
    "    if not module or current_depth >= max_depth:\n",
    "        return functions\n",
    "    \n",
    "    # Get functions from current module\n",
    "    functions.extend(get_module_functions(module, module_name))\n",
    "    \n",
    "    # Get submodules\n",
    "    try:\n",
    "        if hasattr(module, '__path__'):\n",
    "            for importer, modname, ispkg in pkgutil.iter_modules(module.__path__):\n",
    "                try:\n",
    "                    submodule_name = f\"{module_name}.{modname}\"\n",
    "                    submodule = safe_import(submodule_name)\n",
    "                    if submodule:\n",
    "                        functions.extend(get_submodule_functions(\n",
    "                            submodule, submodule_name, max_depth, current_depth + 1\n",
    "                        ))\n",
    "                except:\n",
    "                    continue\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return functions\n",
    "\n",
    "def get_gdal_algorithms():\n",
    "    \"\"\"Extract GDAL/OGR algorithms\"\"\"\n",
    "    algorithms = []\n",
    "    \n",
    "    # GDAL modules to check\n",
    "    gdal_modules = [\n",
    "        'osgeo.gdal',\n",
    "        'osgeo.ogr', \n",
    "        'osgeo.osr',\n",
    "        'osgeo.gdal_array',\n",
    "        'osgeo.gdalconst'\n",
    "    ]\n",
    "    \n",
    "    for module_name in gdal_modules:\n",
    "        module = safe_import(module_name)\n",
    "        if module:\n",
    "            functions = get_module_functions(module, module_name.replace('osgeo.', 'gdal.'))\n",
    "            algorithms.extend(functions)\n",
    "            print(f\" {module_name}: Found {len(functions)} functions\")\n",
    "        else:\n",
    "            print(f\" {module_name}: Not available\")\n",
    "    \n",
    "    return algorithms\n",
    "\n",
    "def get_rasterio_algorithms():\n",
    "    \"\"\"Extract Rasterio algorithms\"\"\"\n",
    "    algorithms = []\n",
    "    \n",
    "    rasterio_modules = [\n",
    "        'rasterio',\n",
    "        'rasterio.features',\n",
    "        'rasterio.mask',\n",
    "        'rasterio.merge',\n",
    "        'rasterio.plot',\n",
    "        'rasterio.sample',\n",
    "        'rasterio.transform',\n",
    "        'rasterio.warp',\n",
    "        'rasterio.windows',\n",
    "        'rasterio.enums',\n",
    "        'rasterio.crs'\n",
    "    ]\n",
    "    \n",
    "    for module_name in rasterio_modules:\n",
    "        module = safe_import(module_name)\n",
    "        if module:\n",
    "            functions = get_module_functions(module, module_name)\n",
    "            algorithms.extend(functions)\n",
    "            print(f\" {module_name}: Found {len(functions)} functions\")\n",
    "        else:\n",
    "            print(f\" {module_name}: Not available\")\n",
    "    \n",
    "    return algorithms\n",
    "\n",
    "def get_shapely_algorithms():\n",
    "    \"\"\"Extract Shapely algorithms\"\"\"\n",
    "    algorithms = []\n",
    "    \n",
    "    shapely_modules = [\n",
    "        'shapely.geometry',\n",
    "        'shapely.ops',\n",
    "        'shapely.affinity',\n",
    "        'shapely.algorithms',\n",
    "        'shapely.predicates',\n",
    "        'shapely.validation',\n",
    "        'shapely.prepared'\n",
    "    ]\n",
    "    \n",
    "    for module_name in shapely_modules:\n",
    "        module = safe_import(module_name)\n",
    "        if module:\n",
    "            functions = get_module_functions(module, module_name)\n",
    "            algorithms.extend(functions)\n",
    "            print(f\" {module_name}: Found {len(functions)} functions\")\n",
    "        else:\n",
    "            print(f\" {module_name}: Not available\")\n",
    "    \n",
    "    return algorithms\n",
    "\n",
    "def get_geopandas_algorithms():\n",
    "    \"\"\"Extract GeoPandas algorithms\"\"\"\n",
    "    algorithms = []\n",
    "    \n",
    "    geopandas_modules = [\n",
    "        'geopandas',\n",
    "        'geopandas.tools',\n",
    "        'geopandas.datasets'\n",
    "    ]\n",
    "    \n",
    "    for module_name in geopandas_modules:\n",
    "        module = safe_import(module_name)\n",
    "        if module:\n",
    "            functions = get_module_functions(module, module_name)\n",
    "            algorithms.extend(functions)\n",
    "            print(f\" {module_name}: Found {len(functions)} functions\")\n",
    "        else:\n",
    "            print(f\" {module_name}: Not available\")\n",
    "    \n",
    "    return algorithms\n",
    "\n",
    "def get_skimage_algorithms():\n",
    "    \"\"\"Extract Scikit-image algorithms\"\"\"\n",
    "    algorithms = []\n",
    "    \n",
    "    skimage_modules = [\n",
    "        'skimage.filters',\n",
    "        'skimage.morphology',\n",
    "        'skimage.segmentation',\n",
    "        'skimage.feature',\n",
    "        'skimage.transform',\n",
    "        'skimage.restoration',\n",
    "        'skimage.exposure',\n",
    "        'skimage.measure',\n",
    "        'skimage.color',\n",
    "        'skimage.util'\n",
    "    ]\n",
    "    \n",
    "    for module_name in skimage_modules:\n",
    "        module = safe_import(module_name)\n",
    "        if module:\n",
    "            functions = get_module_functions(module, module_name)\n",
    "            algorithms.extend(functions)\n",
    "            print(f\" {module_name}: Found {len(functions)} functions\")\n",
    "        else:\n",
    "            print(f\" {module_name}: Not available\")\n",
    "    \n",
    "    return algorithms\n",
    "\n",
    "def get_opencv_algorithms():\n",
    "    \"\"\"Extract OpenCV algorithms with improved error handling\"\"\"\n",
    "    algorithms = []\n",
    "    \n",
    "    opencv_modules = [\n",
    "        'cv2'\n",
    "    ]\n",
    "    \n",
    "    for module_name in opencv_modules:\n",
    "        try:\n",
    "            module = safe_import(module_name)\n",
    "            if module:\n",
    "                functions = get_module_functions(module, module_name)\n",
    "                algorithms.extend(functions)\n",
    "                print(f\" {module_name}: Found {len(functions)} functions\")\n",
    "            else:\n",
    "                print(f\" {module_name}: Not available\")\n",
    "        except Exception:\n",
    "            print(f\" {module_name}: Import failed\")\n",
    "    \n",
    "    return algorithms\n",
    "\n",
    "def get_scipy_algorithms():\n",
    "    \"\"\"Extract SciPy algorithms relevant to geospatial analysis\"\"\"\n",
    "    algorithms = []\n",
    "    \n",
    "    scipy_modules = [\n",
    "        'scipy.ndimage',\n",
    "        'scipy.spatial',\n",
    "        'scipy.interpolate',\n",
    "        'scipy.signal',\n",
    "        'scipy.stats'\n",
    "    ]\n",
    "    \n",
    "    for module_name in scipy_modules:\n",
    "        module = safe_import(module_name)\n",
    "        if module:\n",
    "            functions = get_module_functions(module, module_name)\n",
    "            algorithms.extend(functions)\n",
    "            print(f\" {module_name}: Found {len(functions)} functions\")\n",
    "        else:\n",
    "            print(f\" {module_name}: Not available\")\n",
    "    \n",
    "    return algorithms\n",
    "\n",
    "def get_numpy_algorithms():\n",
    "    \"\"\"Extract NumPy algorithms relevant to geospatial analysis with error suppression\"\"\"\n",
    "    algorithms = []\n",
    "    \n",
    "    numpy_modules = [\n",
    "        'numpy',\n",
    "        'numpy.ma',  # Masked arrays\n",
    "        'numpy.linalg'  # Linear algebra\n",
    "    ]\n",
    "    \n",
    "    for module_name in numpy_modules:\n",
    "        try:\n",
    "            module = safe_import(module_name)\n",
    "            if module:\n",
    "                functions = get_module_functions(module, module_name)\n",
    "                algorithms.extend(functions)\n",
    "                print(f\" {module_name}: Found {len(functions)} functions\")\n",
    "            else:\n",
    "                print(f\" {module_name}: Not available\")\n",
    "        except Exception:\n",
    "            print(f\" {module_name}: Import failed (compatibility issue)\")\n",
    "    \n",
    "    return algorithms\n",
    "\n",
    "def get_other_gis_libraries():\n",
    "    \"\"\"Extract algorithms from other common GIS libraries\"\"\"\n",
    "    algorithms = []\n",
    "    \n",
    "    other_libraries = [\n",
    "        'fiona',\n",
    "        'pyproj',\n",
    "        'cartopy',\n",
    "        'folium',\n",
    "        'xarray',\n",
    "        'rioxarray',\n",
    "        'geopy',\n",
    "        'contextily',\n",
    "        'earthpy',\n",
    "        'rasterstats',\n",
    "        'geoplot',\n",
    "        'plotly.express'\n",
    "    ]\n",
    "    \n",
    "    for module_name in other_libraries:\n",
    "        module = safe_import(module_name)\n",
    "        if module:\n",
    "            functions = get_module_functions(module, module_name)\n",
    "            algorithms.extend(functions)\n",
    "            print(f\" {module_name}: Found {len(functions)} functions\")\n",
    "        else:\n",
    "            print(f\" {module_name}: Not available\")\n",
    "    \n",
    "    return algorithms\n",
    "\n",
    "def categorize_python_function(module_name, function_name):\n",
    "    \"\"\"Categorize Python functions based on module and function name\"\"\"\n",
    "    \n",
    "    module_lower = module_name.lower()\n",
    "    function_lower = function_name.lower()\n",
    "    \n",
    "    # GDAL/OGR specific\n",
    "    if 'gdal' in module_lower or 'ogr' in module_lower:\n",
    "        if any(keyword in function_lower for keyword in ['read', 'open', 'create', 'write', 'driver']):\n",
    "            return 'GDAL I/O'\n",
    "        elif any(keyword in function_lower for keyword in ['transform', 'warp', 'reproject', 'geotransform']):\n",
    "            return 'GDAL Geometric'\n",
    "        elif any(keyword in function_lower for keyword in ['raster', 'band', 'pixel']):\n",
    "            return 'GDAL Raster'\n",
    "        elif any(keyword in function_lower for keyword in ['vector', 'feature', 'geometry', 'layer']):\n",
    "            return 'GDAL Vector'\n",
    "        else:\n",
    "            return 'GDAL General'\n",
    "    \n",
    "    # Rasterio specific\n",
    "    elif 'rasterio' in module_lower:\n",
    "        if 'mask' in module_lower or any(keyword in function_lower for keyword in ['mask', 'clip']):\n",
    "            return 'Rasterio Masking'\n",
    "        elif 'warp' in module_lower or any(keyword in function_lower for keyword in ['warp', 'reproject', 'transform']):\n",
    "            return 'Rasterio Warping'\n",
    "        elif 'merge' in module_lower or any(keyword in function_lower for keyword in ['merge', 'mosaic']):\n",
    "            return 'Rasterio Merging'\n",
    "        elif any(keyword in function_lower for keyword in ['read', 'write', 'open']):\n",
    "            return 'Rasterio I/O'\n",
    "        else:\n",
    "            return 'Rasterio General'\n",
    "    \n",
    "    # Shapely specific\n",
    "    elif 'shapely' in module_lower:\n",
    "        if 'ops' in module_lower or any(keyword in function_lower for keyword in ['union', 'intersection', 'difference', 'buffer']):\n",
    "            return 'Shapely Operations'\n",
    "        elif 'affinity' in module_lower or any(keyword in function_lower for keyword in ['rotate', 'scale', 'translate', 'skew']):\n",
    "            return 'Shapely Transformations'\n",
    "        elif any(keyword in function_lower for keyword in ['point', 'line', 'polygon', 'geometry']):\n",
    "            return 'Shapely Geometry'\n",
    "        else:\n",
    "            return 'Shapely General'\n",
    "    \n",
    "    # GeoPandas specific\n",
    "    elif 'geopandas' in module_lower:\n",
    "        if any(keyword in function_lower for keyword in ['overlay', 'sjoin', 'spatial']):\n",
    "            return 'GeoPandas Spatial'\n",
    "        elif any(keyword in function_lower for keyword in ['read', 'write', 'to_']):\n",
    "            return 'GeoPandas I/O'\n",
    "        else:\n",
    "            return 'GeoPandas General'\n",
    "    \n",
    "    # Scikit-image specific\n",
    "    elif 'skimage' in module_lower:\n",
    "        if 'filters' in module_lower or any(keyword in function_lower for keyword in ['filter', 'smooth', 'gaussian', 'median']):\n",
    "            return 'Skimage Filtering'\n",
    "        elif 'morphology' in module_lower or any(keyword in function_lower for keyword in ['erosion', 'dilation', 'opening', 'closing']):\n",
    "            return 'Skimage Morphology'\n",
    "        elif 'segmentation' in module_lower or any(keyword in function_lower for keyword in ['segment', 'watershed', 'region']):\n",
    "            return 'Skimage Segmentation'\n",
    "        elif 'feature' in module_lower or any(keyword in function_lower for keyword in ['edge', 'corner', 'blob', 'peak']):\n",
    "            return 'Skimage Features'\n",
    "        elif 'transform' in module_lower or any(keyword in function_lower for keyword in ['resize', 'rotate', 'warp']):\n",
    "            return 'Skimage Transform'\n",
    "        elif 'measure' in module_lower or any(keyword in function_lower for keyword in ['label', 'properties', 'area', 'perimeter']):\n",
    "            return 'Skimage Measurement'\n",
    "        else:\n",
    "            return 'Skimage General'\n",
    "    \n",
    "    # OpenCV specific\n",
    "    elif 'cv2' in module_lower:\n",
    "        if any(keyword in function_lower for keyword in ['filter', 'blur', 'smooth', 'gaussian', 'bilateral']):\n",
    "            return 'OpenCV Filtering'\n",
    "        elif any(keyword in function_lower for keyword in ['morphology', 'erode', 'dilate', 'opening', 'closing']):\n",
    "            return 'OpenCV Morphology'\n",
    "        elif any(keyword in function_lower for keyword in ['edge', 'canny', 'sobel', 'laplacian']):\n",
    "            return 'OpenCV Edge Detection'\n",
    "        elif any(keyword in function_lower for keyword in ['transform', 'warp', 'perspective', 'affine']):\n",
    "            return 'OpenCV Transform'\n",
    "        elif any(keyword in function_lower for keyword in ['feature', 'corner', 'keypoint', 'descriptor']):\n",
    "            return 'OpenCV Features'\n",
    "        elif any(keyword in function_lower for keyword in ['contour', 'hull', 'moments']):\n",
    "            return 'OpenCV Contours'\n",
    "        else:\n",
    "            return 'OpenCV General'\n",
    "    \n",
    "    # SciPy specific\n",
    "    elif 'scipy' in module_lower:\n",
    "        if 'ndimage' in module_lower:\n",
    "            return 'SciPy Image Processing'\n",
    "        elif 'spatial' in module_lower:\n",
    "            return 'SciPy Spatial'\n",
    "        elif 'interpolate' in module_lower:\n",
    "            return 'SciPy Interpolation'\n",
    "        elif 'signal' in module_lower:\n",
    "            return 'SciPy Signal Processing'\n",
    "        elif 'stats' in module_lower:\n",
    "            return 'SciPy Statistics'\n",
    "        else:\n",
    "            return 'SciPy General'\n",
    "    \n",
    "    # NumPy specific\n",
    "    elif 'numpy' in module_lower:\n",
    "        if any(keyword in function_lower for keyword in ['array', 'matrix', 'reshape', 'transpose']):\n",
    "            return 'NumPy Arrays'\n",
    "        elif any(keyword in function_lower for keyword in ['math', 'sum', 'mean', 'std', 'var', 'max', 'min']):\n",
    "            return 'NumPy Math'\n",
    "        elif 'linalg' in module_lower:\n",
    "            return 'NumPy Linear Algebra'\n",
    "        elif 'ma' in module_lower:\n",
    "            return 'NumPy Masked Arrays'\n",
    "        else:\n",
    "            return 'NumPy General'\n",
    "    \n",
    "    # Other libraries\n",
    "    elif any(lib in module_lower for lib in ['fiona', 'pyproj', 'cartopy', 'folium']):\n",
    "        return f\"{module_name.split('.')[0].title()} Tools\"\n",
    "    \n",
    "    # Generic categorization\n",
    "    elif any(keyword in function_lower for keyword in ['read', 'write', 'load', 'save', 'open']):\n",
    "        return 'I/O Operations'\n",
    "    elif any(keyword in function_lower for keyword in ['plot', 'show', 'display', 'visualize']):\n",
    "        return 'Visualization'\n",
    "    elif any(keyword in function_lower for keyword in ['transform', 'warp', 'project', 'convert']):\n",
    "        return 'Transformations'\n",
    "    elif any(keyword in function_lower for keyword in ['filter', 'smooth', 'enhance', 'process']):\n",
    "        return 'Processing'\n",
    "    elif any(keyword in function_lower for keyword in ['analyze', 'calculate', 'compute', 'measure']):\n",
    "        return 'Analysis'\n",
    "    else:\n",
    "        return 'General'\n",
    "\n",
    "def merge_algorithms(algorithm_lists):\n",
    "    \"\"\"Merge algorithm lists and remove duplicates\"\"\"\n",
    "    seen = set()\n",
    "    merged = []\n",
    "    \n",
    "    for alg_list in algorithm_lists:\n",
    "        for alg in alg_list:\n",
    "            alg_id = alg['algorithm_id']\n",
    "            \n",
    "            if alg_id not in seen:\n",
    "                seen.add(alg_id)\n",
    "                merged.append(alg)\n",
    "    \n",
    "    return merged\n",
    "\n",
    "def export_python_algorithms():\n",
    "    \"\"\"Export all Python geospatial algorithms to CSV\"\"\"\n",
    "    \n",
    "    print(\"=== Python Geospatial Libraries Algorithm Extraction ===\\n\")\n",
    "    \n",
    "    # Detection methods for different library groups\n",
    "    detection_methods = [\n",
    "        (\"GDAL/OGR\", get_gdal_algorithms),\n",
    "        (\"Rasterio\", get_rasterio_algorithms),\n",
    "        (\"Shapely\", get_shapely_algorithms),\n",
    "        (\"GeoPandas\", get_geopandas_algorithms),\n",
    "        (\"Scikit-image\", get_skimage_algorithms),\n",
    "        (\"OpenCV\", get_opencv_algorithms),\n",
    "        (\"SciPy\", get_scipy_algorithms),\n",
    "        (\"NumPy\", get_numpy_algorithms),\n",
    "        (\"Other GIS Libraries\", get_other_gis_libraries)\n",
    "    ]\n",
    "    \n",
    "    all_algorithms = []\n",
    "    \n",
    "    for method_name, method_func in detection_methods:\n",
    "        print(f\"\\n--- Processing {method_name} ---\")\n",
    "        try:\n",
    "            algorithms = method_func()\n",
    "            if algorithms:\n",
    "                all_algorithms.append(algorithms)\n",
    "                print(f\" {method_name}: Total {len(algorithms)} functions extracted\")\n",
    "            else:\n",
    "                print(f\" {method_name}: No functions found\")\n",
    "        except Exception as e:\n",
    "            print(f\" {method_name}: Failed (compatibility issue)\")\n",
    "    \n",
    "    # Merge all results\n",
    "    if all_algorithms:\n",
    "        merged_algorithms = merge_algorithms(all_algorithms)\n",
    "        \n",
    "        # Write to CSV\n",
    "        csv_path = '/workspace/python_gis_algorithms.csv'\n",
    "        with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            fieldnames = ['tool', 'provider', 'algorithm_id', 'display_name', 'group', 'detection_method']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(merged_algorithms)\n",
    "        \n",
    "        print(f\"\\n=== Results ===\")\n",
    "        print(f\" Total algorithms found: {len(merged_algorithms)}\")\n",
    "        print(f\" CSV saved to: {csv_path}\")\n",
    "        \n",
    "        # Provider summary\n",
    "        providers = {}\n",
    "        for alg in merged_algorithms:\n",
    "            provider = alg['provider']\n",
    "            providers[provider] = providers.get(provider, 0) + 1\n",
    "        \n",
    "        print(f\"\\nTop providers:\")\n",
    "        sorted_providers = sorted(providers.items(), key=lambda x: x[1], reverse=True)\n",
    "        for provider, count in sorted_providers[:10]:\n",
    "            print(f\"  {provider}: {count}\")\n",
    "        \n",
    "        # Category summary\n",
    "        categories = {}\n",
    "        for alg in merged_algorithms:\n",
    "            cat = alg['group']\n",
    "            categories[cat] = categories.get(cat, 0) + 1\n",
    "        \n",
    "        print(f\"\\nTop categories:\")\n",
    "        sorted_cats = sorted(categories.items(), key=lambda x: x[1], reverse=True)\n",
    "        for cat, count in sorted_cats[:15]:\n",
    "            print(f\"  {cat}: {count}\")\n",
    "        \n",
    "        return len(merged_algorithms)\n",
    "    else:\n",
    "        print(\" No Python algorithms found\")\n",
    "        return 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    total = export_python_algorithms()\n",
    "    print(f\"\\nFinal count: {total} Python geospatial algorithms catalogued\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35d042cb-9f78-4454-a85f-39b90b2a58f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== QGIS Processing Framework Algorithm Extraction ===\n",
      "\n",
      "\n",
      "--- Trying Processing Registry ---\n",
      "QGIS environment configured (0 Python paths added)\n",
      " QGIS environment setup failed\n",
      " Processing Registry: No algorithms found\n",
      "\n",
      "--- Trying CLI List ---\n",
      " Found QGIS CLI: qgis_process\n",
      " CLI list: Found 379 algorithms\n",
      " CLI List: Found 379 algorithms\n",
      "\n",
      "--- Trying Detailed Help ---\n",
      " Found QGIS CLI: qgis_process\n",
      " CLI list: Found 379 algorithms\n",
      "Getting detailed help for 379 algorithms...\n",
      "  Progress: 1/100\n",
      "  Progress: 21/100\n",
      "  Progress: 41/100\n",
      "  Progress: 61/100\n",
      "  Progress: 81/100\n",
      " Detailed help: Found 100 algorithms\n",
      " Detailed Help: Found 100 algorithms\n",
      "\n",
      "--- Trying Config Files ---\n",
      " Config files (/opt/conda/envs/pygile/share/qgis/python/plugins): Found 30 algorithms\n",
      " Config Files: Found 30 algorithms\n",
      "\n",
      "=== Results ===\n",
      " Total algorithms found: 398\n",
      " CSV saved to: /workspace/qgis_algorithms.csv\n",
      "\n",
      "Top providers:\n",
      "  native: 266\n",
      "  gdal: 57\n",
      "  qgis: 38\n",
      "  pdal: 17\n",
      "  plugin_tests: 7\n",
      "  plugin_qgis: 3\n",
      "  plugin_gui: 3\n",
      "  plugin_grassprovider: 2\n",
      "  plugin_gdal: 2\n",
      "  3d: 1\n",
      "\n",
      "Top categories:\n",
      "  QGIS General: 304\n",
      "  GDAL General: 29\n",
      "  Plugin Algorithms: 19\n",
      "  GDAL Raster: 16\n",
      "  Pdal General: 11\n",
      "  GDAL Vector: 9\n",
      "  Data Conversion: 4\n",
      "  GDAL Transform: 3\n",
      "  3D General: 1\n",
      "  Geoprocessing: 1\n",
      "  Data Management: 1\n",
      "\n",
      "Detection methods:\n",
      "  cli_list: 379\n",
      "  config_files: 19\n",
      "\n",
      "Final count: 398 QGIS algorithms catalogued\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "QGIS Processing Framework algorithm extraction\n",
    "Extracts algorithms from QGIS Processing providers including QGIS, GDAL, GRASS, SAGA, etc.\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import subprocess\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "\n",
    "def setup_qgis_environment():\n",
    "    \"\"\"Setup QGIS Python environment\"\"\"\n",
    "    \n",
    "    # Common QGIS Python paths\n",
    "    qgis_python_paths = [\n",
    "        '/usr/share/qgis/python',\n",
    "        '/usr/lib/python3/dist-packages/qgis',\n",
    "        '/opt/conda/envs/pygile/share/qgis/python',\n",
    "        '/Applications/QGIS.app/Contents/Resources/python',\n",
    "        'C:/Program Files/QGIS 3.*/apps/qgis/python',\n",
    "        '/usr/local/share/qgis/python'\n",
    "    ]\n",
    "    \n",
    "    # Add QGIS Python paths\n",
    "    paths_added = 0\n",
    "    for path in qgis_python_paths:\n",
    "        if os.path.exists(path) and path not in sys.path:\n",
    "            sys.path.insert(0, path)\n",
    "            paths_added += 1\n",
    "    \n",
    "    # Set QGIS environment variables\n",
    "    qgis_prefixes = ['/usr', '/opt/conda/envs/pygile', '/Applications/QGIS.app/Contents/MacOS']\n",
    "    \n",
    "    for prefix in qgis_prefixes:\n",
    "        if os.path.exists(f\"{prefix}/share/qgis\"):\n",
    "            os.environ['QGIS_PREFIX_PATH'] = prefix\n",
    "            break\n",
    "    \n",
    "    # Set additional QGIS paths\n",
    "    if 'QGIS_PREFIX_PATH' in os.environ:\n",
    "        qgis_prefix = os.environ['QGIS_PREFIX_PATH']\n",
    "        os.environ['QT_QPA_PLATFORM'] = 'offscreen'  # For headless operation\n",
    "        \n",
    "        # Add to Python path\n",
    "        qgis_python = f\"{qgis_prefix}/share/qgis/python\"\n",
    "        if os.path.exists(qgis_python) and qgis_python not in sys.path:\n",
    "            sys.path.insert(0, qgis_python)\n",
    "            paths_added += 1\n",
    "    \n",
    "    print(f\"QGIS environment configured ({paths_added} Python paths added)\")\n",
    "    return paths_added > 0\n",
    "\n",
    "def initialize_qgis():\n",
    "    \"\"\"Initialize QGIS application for processing\"\"\"\n",
    "    \n",
    "    try:\n",
    "        from qgis.core import QgsApplication, QgsProcessingRegistry\n",
    "        from qgis.analysis import QgsNativeAlgorithms\n",
    "        \n",
    "        # Initialize QGIS Application\n",
    "        QgsApplication.setPrefixPath(os.environ.get('QGIS_PREFIX_PATH', '/usr'), True)\n",
    "        qgs = QgsApplication([], False)\n",
    "        qgs.initQgis()\n",
    "        \n",
    "        # Initialize processing\n",
    "        from processing.core.Processing import Processing\n",
    "        Processing.initialize()\n",
    "        \n",
    "        print(\" QGIS application initialized successfully\")\n",
    "        return qgs, QgsProcessingRegistry.algorithmRegistry()\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(f\" QGIS import failed: {str(e)[:100]}...\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\" QGIS initialization failed: {str(e)[:100]}...\")\n",
    "        return None, None\n",
    "\n",
    "def get_qgis_processing_algorithms():\n",
    "    \"\"\"Extract algorithms from QGIS Processing framework\"\"\"\n",
    "    algorithms = []\n",
    "    \n",
    "    if not setup_qgis_environment():\n",
    "        print(\" QGIS environment setup failed\")\n",
    "        return algorithms\n",
    "    \n",
    "    qgs, registry = initialize_qgis()\n",
    "    \n",
    "    if not registry:\n",
    "        print(\" QGIS Processing registry not available\")\n",
    "        return algorithms\n",
    "    \n",
    "    try:\n",
    "        # Get all algorithm providers\n",
    "        providers = registry.providers()\n",
    "        \n",
    "        print(f\"Found {len(providers)} processing providers\")\n",
    "        \n",
    "        for provider in providers:\n",
    "            provider_id = provider.id()\n",
    "            provider_name = provider.name()\n",
    "            \n",
    "            # Get algorithms from this provider\n",
    "            alg_ids = provider.algorithmIds()\n",
    "            \n",
    "            provider_algorithms = []\n",
    "            \n",
    "            for alg_id in alg_ids:\n",
    "                try:\n",
    "                    algorithm = registry.algorithmById(alg_id)\n",
    "                    \n",
    "                    if algorithm:\n",
    "                        # Get algorithm details\n",
    "                        display_name = algorithm.displayName()\n",
    "                        group = algorithm.group()\n",
    "                        short_help = \"\"\n",
    "                        \n",
    "                        try:\n",
    "                            short_help = algorithm.shortHelpString()\n",
    "                        except:\n",
    "                            pass\n",
    "                        \n",
    "                        # Use short help as description, fallback to display name\n",
    "                        description = short_help if short_help else display_name\n",
    "                        if len(description) > 200:\n",
    "                            description = description[:200] + \"...\"\n",
    "                        \n",
    "                        # Categorize based on provider and group\n",
    "                        category = categorize_qgis_algorithm(provider_id, group, alg_id)\n",
    "                        \n",
    "                        provider_algorithms.append({\n",
    "                            'tool': 'QGIS',\n",
    "                            'provider': provider_id,\n",
    "                            'algorithm_id': alg_id,\n",
    "                            'display_name': description,\n",
    "                            'group': category,\n",
    "                            'detection_method': 'processing_registry'\n",
    "                        })\n",
    "                \n",
    "                except Exception as e:\n",
    "                    # Add basic entry if detailed extraction fails\n",
    "                    provider_algorithms.append({\n",
    "                        'tool': 'QGIS',\n",
    "                        'provider': provider_id,\n",
    "                        'algorithm_id': alg_id,\n",
    "                        'display_name': alg_id.split(':')[-1] if ':' in alg_id else alg_id,\n",
    "                        'group': categorize_qgis_algorithm(provider_id, \"\", alg_id),\n",
    "                        'detection_method': 'processing_registry'\n",
    "                    })\n",
    "            \n",
    "            if provider_algorithms:\n",
    "                algorithms.extend(provider_algorithms)\n",
    "                print(f\" {provider_name} ({provider_id}): Found {len(provider_algorithms)} algorithms\")\n",
    "            else:\n",
    "                print(f\" {provider_name} ({provider_id}): No algorithms found\")\n",
    "        \n",
    "        # Clean up QGIS\n",
    "        if qgs:\n",
    "            qgs.exitQgis()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting QGIS algorithms: {str(e)[:100]}...\")\n",
    "    \n",
    "    return algorithms\n",
    "\n",
    "def get_qgis_cli_algorithms():\n",
    "    \"\"\"Extract QGIS algorithms using CLI tools\"\"\"\n",
    "    algorithms = []\n",
    "    \n",
    "    # Try to find QGIS processing CLI tools\n",
    "    qgis_commands = [\n",
    "        'qgis_process',\n",
    "        'qgis3_process', \n",
    "        'qgis-ltr_process',\n",
    "        '/usr/bin/qgis_process',\n",
    "        '/opt/conda/envs/pygile/bin/qgis_process'\n",
    "    ]\n",
    "    \n",
    "    qgis_cmd = None\n",
    "    for cmd in qgis_commands:\n",
    "        try:\n",
    "            result = subprocess.run([cmd, '--version'], capture_output=True, text=True, timeout=10)\n",
    "            if result.returncode == 0:\n",
    "                qgis_cmd = cmd\n",
    "                print(f\" Found QGIS CLI: {cmd}\")\n",
    "                break\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if not qgis_cmd:\n",
    "        print(\" QGIS CLI tools not found\")\n",
    "        return algorithms\n",
    "    \n",
    "    try:\n",
    "        # Get list of algorithms\n",
    "        result = subprocess.run([qgis_cmd, 'list'], capture_output=True, text=True, timeout=30)\n",
    "        \n",
    "        if result.returncode == 0 and result.stdout:\n",
    "            lines = result.stdout.split('\\n')\n",
    "            \n",
    "            current_provider = \"\"\n",
    "            \n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                \n",
    "                if not line:\n",
    "                    continue\n",
    "                \n",
    "                # Check if this is a provider header\n",
    "                if line.endswith(':') and not line.startswith(' '):\n",
    "                    current_provider = line.rstrip(':')\n",
    "                    continue\n",
    "                \n",
    "                # Check if this is an algorithm\n",
    "                if line.startswith(' ') or ':' in line:\n",
    "                    # Parse algorithm line\n",
    "                    if ':' in line:\n",
    "                        alg_id = line.strip()\n",
    "                        provider_id = alg_id.split(':')[0] if ':' in alg_id else current_provider\n",
    "                        alg_name = alg_id.split(':')[-1] if ':' in alg_id else alg_id\n",
    "                    else:\n",
    "                        alg_name = line.strip()\n",
    "                        alg_id = f\"{current_provider}:{alg_name}\" if current_provider else alg_name\n",
    "                        provider_id = current_provider\n",
    "                    \n",
    "                    if alg_name and len(alg_name) > 1:\n",
    "                        algorithms.append({\n",
    "                            'tool': 'QGIS',\n",
    "                            'provider': provider_id,\n",
    "                            'algorithm_id': alg_id,\n",
    "                            'display_name': alg_name,\n",
    "                            'group': categorize_qgis_algorithm(provider_id, \"\", alg_id),\n",
    "                            'detection_method': 'cli_list'\n",
    "                        })\n",
    "            \n",
    "            print(f\" CLI list: Found {len(algorithms)} algorithms\")\n",
    "        else:\n",
    "            print(f\" CLI list failed: {result.stderr[:100]}...\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\" CLI extraction failed: {str(e)[:50]}...\")\n",
    "    \n",
    "    return algorithms\n",
    "\n",
    "def get_qgis_help_detailed():\n",
    "    \"\"\"Get detailed help for QGIS algorithms\"\"\"\n",
    "    algorithms = []\n",
    "    \n",
    "    # First get basic list\n",
    "    base_algorithms = get_qgis_cli_algorithms()\n",
    "    \n",
    "    if not base_algorithms:\n",
    "        return algorithms\n",
    "    \n",
    "    qgis_cmd = None\n",
    "    qgis_commands = ['qgis_process', 'qgis3_process', 'qgis-ltr_process']\n",
    "    \n",
    "    for cmd in qgis_commands:\n",
    "        try:\n",
    "            result = subprocess.run([cmd, '--version'], capture_output=True, text=True, timeout=5)\n",
    "            if result.returncode == 0:\n",
    "                qgis_cmd = cmd\n",
    "                break\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if not qgis_cmd:\n",
    "        return algorithms\n",
    "    \n",
    "    print(f\"Getting detailed help for {len(base_algorithms)} algorithms...\")\n",
    "    \n",
    "    # Limit to reasonable number for detailed extraction\n",
    "    sample_algorithms = base_algorithms[:100] if len(base_algorithms) > 100 else base_algorithms\n",
    "    \n",
    "    for i, alg_info in enumerate(sample_algorithms):\n",
    "        alg_id = alg_info['algorithm_id']\n",
    "        \n",
    "        if i % 20 == 0:\n",
    "            print(f\"  Progress: {i+1}/{len(sample_algorithms)}\")\n",
    "        \n",
    "        try:\n",
    "            # Get help for individual algorithm\n",
    "            result = subprocess.run([qgis_cmd, 'help', alg_id], \n",
    "                                  capture_output=True, \n",
    "                                  text=True, \n",
    "                                  timeout=10)\n",
    "            \n",
    "            if result.returncode == 0 and result.stdout:\n",
    "                output = result.stdout\n",
    "                \n",
    "                # Extract description from help output\n",
    "                description = alg_id.split(':')[-1] if ':' in alg_id else alg_id\n",
    "                \n",
    "                # Look for description patterns\n",
    "                desc_patterns = [\n",
    "                    r'Description:\\s*(.+?)(?:\\n\\n|\\nUsage:|\\nArguments:)',\n",
    "                    r'DESCRIPTION:\\s*(.+?)(?:\\n\\n|\\nUSAGE:|\\nARGUMENTS:)',\n",
    "                    r'Summary:\\s*(.+?)(?:\\n)',\n",
    "                    r'Purpose:\\s*(.+?)(?:\\n)'\n",
    "                ]\n",
    "                \n",
    "                for pattern in desc_patterns:\n",
    "                    match = re.search(pattern, output, re.DOTALL | re.IGNORECASE)\n",
    "                    if match:\n",
    "                        desc = match.group(1).strip()\n",
    "                        if len(desc) > len(description) and len(desc) < 300:\n",
    "                            description = desc\n",
    "                            break\n",
    "                \n",
    "                # Clean up description\n",
    "                description = ' '.join(description.split())\n",
    "                \n",
    "                algorithms.append({\n",
    "                    'tool': 'QGIS',\n",
    "                    'provider': alg_info['provider'],\n",
    "                    'algorithm_id': alg_id,\n",
    "                    'display_name': description,\n",
    "                    'group': alg_info['group'],\n",
    "                    'detection_method': 'cli_detailed_help'\n",
    "                })\n",
    "            else:\n",
    "                # Keep original if help fails\n",
    "                algorithms.append(alg_info)\n",
    "                \n",
    "        except:\n",
    "            # Keep original if help fails\n",
    "            algorithms.append(alg_info)\n",
    "    \n",
    "    print(f\" Detailed help: Found {len(algorithms)} algorithms\")\n",
    "    return algorithms\n",
    "\n",
    "def get_qgis_config_files():\n",
    "    \"\"\"Extract algorithms from QGIS configuration and plugin files\"\"\"\n",
    "    algorithms = []\n",
    "    \n",
    "    # Look for QGIS plugin directories\n",
    "    qgis_plugin_paths = [\n",
    "        '/usr/share/qgis/python/plugins',\n",
    "        '/opt/conda/envs/pygile/share/qgis/python/plugins',\n",
    "        os.path.expanduser('~/.local/share/QGIS/QGIS3/profiles/default/python/plugins'),\n",
    "        '/Applications/QGIS.app/Contents/Resources/python/plugins'\n",
    "    ]\n",
    "    \n",
    "    algorithm_files_found = 0\n",
    "    \n",
    "    for plugin_path in qgis_plugin_paths:\n",
    "        if os.path.exists(plugin_path):\n",
    "            try:\n",
    "                # Look for processing provider files\n",
    "                for root, dirs, files in os.walk(plugin_path):\n",
    "                    for file in files:\n",
    "                        if file.endswith('.py') and any(keyword in file.lower() for keyword in ['algorithm', 'processing', 'provider']):\n",
    "                            file_path = os.path.join(root, file)\n",
    "                            algorithm_files_found += 1\n",
    "                            \n",
    "                            try:\n",
    "                                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                                    content = f.read()\n",
    "                                    \n",
    "                                    # Look for algorithm class definitions\n",
    "                                    algorithm_patterns = [\n",
    "                                        r'class\\s+(\\w+)\\s*\\(\\s*QgsProcessingAlgorithm',\n",
    "                                        r'class\\s+(\\w+)Algorithm',\n",
    "                                        r'def\\s+createAlgorithm.*name.*[\"\\']([^\"\\']+)[\"\\']',\n",
    "                                        r'ALGORITHM_NAME\\s*=\\s*[\"\\']([^\"\\']+)[\"\\']'\n",
    "                                    ]\n",
    "                                    \n",
    "                                    for pattern in algorithm_patterns:\n",
    "                                        matches = re.findall(pattern, content, re.IGNORECASE)\n",
    "                                        for match in matches:\n",
    "                                            if len(match) > 2:\n",
    "                                                plugin_name = os.path.basename(os.path.dirname(file_path))\n",
    "                                                \n",
    "                                                algorithms.append({\n",
    "                                                    'tool': 'QGIS',\n",
    "                                                    'provider': f'plugin_{plugin_name}',\n",
    "                                                    'algorithm_id': f'{plugin_name}:{match}',\n",
    "                                                    'display_name': match,\n",
    "                                                    'group': 'Plugin Algorithms',\n",
    "                                                    'detection_method': 'config_files'\n",
    "                                                })\n",
    "                            except:\n",
    "                                continue\n",
    "                \n",
    "                if algorithms:\n",
    "                    print(f\" Config files ({plugin_path}): Found {len(algorithms)} algorithms\")\n",
    "                    break\n",
    "                    \n",
    "            except Exception as e:\n",
    "                continue\n",
    "    \n",
    "    if not algorithms:\n",
    "        print(f\" Config files: No algorithms found (checked {algorithm_files_found} files)\")\n",
    "    \n",
    "    return algorithms\n",
    "\n",
    "def categorize_qgis_algorithm(provider_id, group, algorithm_id):\n",
    "    \"\"\"Categorize QGIS algorithms based on provider and algorithm details\"\"\"\n",
    "    \n",
    "    provider_lower = provider_id.lower() if provider_id else \"\"\n",
    "    group_lower = group.lower() if group else \"\"\n",
    "    alg_lower = algorithm_id.lower() if algorithm_id else \"\"\n",
    "    \n",
    "    # Provider-specific categorization\n",
    "    if provider_lower == 'qgis' or provider_lower == 'native':\n",
    "        if any(keyword in group_lower for keyword in ['vector', 'geometry']):\n",
    "            return 'QGIS Vector'\n",
    "        elif any(keyword in group_lower for keyword in ['raster', 'analysis']):\n",
    "            return 'QGIS Raster'\n",
    "        elif any(keyword in group_lower for keyword in ['database', 'table']):\n",
    "            return 'QGIS Database'\n",
    "        elif any(keyword in group_lower for keyword in ['cartography', 'layout']):\n",
    "            return 'QGIS Cartography'\n",
    "        else:\n",
    "            return 'QGIS General'\n",
    "    \n",
    "    elif provider_lower == 'gdal':\n",
    "        if any(keyword in alg_lower for keyword in ['raster', 'grid', 'dem']):\n",
    "            return 'GDAL Raster'\n",
    "        elif any(keyword in alg_lower for keyword in ['vector', 'ogr', 'layer']):\n",
    "            return 'GDAL Vector'\n",
    "        elif any(keyword in alg_lower for keyword in ['warp', 'transform', 'project']):\n",
    "            return 'GDAL Transform'\n",
    "        else:\n",
    "            return 'GDAL General'\n",
    "    \n",
    "    elif provider_lower == 'grass' or provider_lower.startswith('grass'):\n",
    "        if any(keyword in alg_lower for keyword in ['r.', 'raster']):\n",
    "            return 'GRASS Raster'\n",
    "        elif any(keyword in alg_lower for keyword in ['v.', 'vector']):\n",
    "            return 'GRASS Vector'\n",
    "        elif any(keyword in alg_lower for keyword in ['i.', 'imagery']):\n",
    "            return 'GRASS Imagery'\n",
    "        elif any(keyword in alg_lower for keyword in ['d.', 'display']):\n",
    "            return 'GRASS Display'\n",
    "        else:\n",
    "            return 'GRASS General'\n",
    "    \n",
    "    elif provider_lower == 'saga' or provider_lower.startswith('saga'):\n",
    "        if any(keyword in alg_lower for keyword in ['grid', 'raster']):\n",
    "            return 'SAGA Grid'\n",
    "        elif any(keyword in alg_lower for keyword in ['shapes', 'vector']):\n",
    "            return 'SAGA Vector'\n",
    "        elif any(keyword in alg_lower for keyword in ['terrain', 'morphometry']):\n",
    "            return 'SAGA Terrain'\n",
    "        elif any(keyword in alg_lower for keyword in ['imagery', 'classification']):\n",
    "            return 'SAGA Imagery'\n",
    "        else:\n",
    "            return 'SAGA General'\n",
    "    \n",
    "    elif provider_lower == 'otb':\n",
    "        return 'OTB Processing'\n",
    "    \n",
    "    elif provider_lower == 'r' or provider_lower.startswith('r:'):\n",
    "        return 'R Scripts'\n",
    "    \n",
    "    elif 'plugin' in provider_lower:\n",
    "        return 'Plugin Algorithms'\n",
    "    \n",
    "    # Generic categorization based on algorithm name\n",
    "    elif any(keyword in alg_lower for keyword in ['buffer', 'clip', 'intersect', 'union', 'difference']):\n",
    "        return 'Geoprocessing'\n",
    "    elif any(keyword in alg_lower for keyword in ['interpolat', 'grid', 'surface']):\n",
    "        return 'Interpolation'\n",
    "    elif any(keyword in alg_lower for keyword in ['network', 'routing', 'shortest']):\n",
    "        return 'Network Analysis'\n",
    "    elif any(keyword in alg_lower for keyword in ['statistic', 'summary', 'count']):\n",
    "        return 'Statistics'\n",
    "    elif any(keyword in alg_lower for keyword in ['join', 'merge', 'append']):\n",
    "        return 'Data Management'\n",
    "    elif any(keyword in alg_lower for keyword in ['export', 'import', 'convert']):\n",
    "        return 'Data Conversion'\n",
    "    else:\n",
    "        return f'{provider_id.title()} General' if provider_id else 'General'\n",
    "\n",
    "def merge_algorithms(algorithm_lists):\n",
    "    \"\"\"Merge algorithm lists and remove duplicates\"\"\"\n",
    "    seen = {}\n",
    "    merged = []\n",
    "    \n",
    "    for alg_list in algorithm_lists:\n",
    "        for alg in alg_list:\n",
    "            alg_id = alg['algorithm_id']\n",
    "            \n",
    "            if alg_id not in seen:\n",
    "                seen[alg_id] = alg\n",
    "                merged.append(alg)\n",
    "            else:\n",
    "                # Update existing entry with better description and additional detection method\n",
    "                existing = seen[alg_id]\n",
    "                \n",
    "                # Use longer, more descriptive display name\n",
    "                if len(alg['display_name']) > len(existing['display_name']):\n",
    "                    existing['display_name'] = alg['display_name']\n",
    "                \n",
    "                # Combine detection methods\n",
    "                if alg['detection_method'] not in existing['detection_method']:\n",
    "                    existing['detection_method'] += f\", {alg['detection_method']}\"\n",
    "    \n",
    "    return merged\n",
    "\n",
    "def export_qgis_algorithms():\n",
    "    \"\"\"Export all QGIS algorithms to CSV\"\"\"\n",
    "    \n",
    "    print(\"=== QGIS Processing Framework Algorithm Extraction ===\\n\")\n",
    "    \n",
    "    # Detection methods\n",
    "    detection_methods = [\n",
    "        (\"Processing Registry\", get_qgis_processing_algorithms),\n",
    "        (\"CLI List\", get_qgis_cli_algorithms),\n",
    "        (\"Detailed Help\", get_qgis_help_detailed),\n",
    "        (\"Config Files\", get_qgis_config_files)\n",
    "    ]\n",
    "    \n",
    "    all_algorithms = []\n",
    "    \n",
    "    for method_name, method_func in detection_methods:\n",
    "        print(f\"\\n--- Trying {method_name} ---\")\n",
    "        try:\n",
    "            algorithms = method_func()\n",
    "            if algorithms:\n",
    "                all_algorithms.append(algorithms)\n",
    "                print(f\" {method_name}: Found {len(algorithms)} algorithms\")\n",
    "            else:\n",
    "                print(f\" {method_name}: No algorithms found\")\n",
    "        except Exception as e:\n",
    "            print(f\" {method_name}: Failed ({str(e)[:50]}...)\")\n",
    "    \n",
    "    # Merge all results\n",
    "    if all_algorithms:\n",
    "        merged_algorithms = merge_algorithms(all_algorithms)\n",
    "        \n",
    "        # Write to CSV\n",
    "        csv_path = '/workspace/qgis_algorithms.csv'\n",
    "        with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            fieldnames = ['tool', 'provider', 'algorithm_id', 'display_name', 'group', 'detection_method']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(merged_algorithms)\n",
    "        \n",
    "        print(f\"\\n=== Results ===\")\n",
    "        print(f\" Total algorithms found: {len(merged_algorithms)}\")\n",
    "        print(f\" CSV saved to: {csv_path}\")\n",
    "        \n",
    "        # Provider summary\n",
    "        providers = {}\n",
    "        for alg in merged_algorithms:\n",
    "            provider = alg['provider']\n",
    "            providers[provider] = providers.get(provider, 0) + 1\n",
    "        \n",
    "        print(f\"\\nTop providers:\")\n",
    "        sorted_providers = sorted(providers.items(), key=lambda x: x[1], reverse=True)\n",
    "        for provider, count in sorted_providers[:10]:\n",
    "            print(f\"  {provider}: {count}\")\n",
    "        \n",
    "        # Category summary\n",
    "        categories = {}\n",
    "        for alg in merged_algorithms:\n",
    "            cat = alg['group']\n",
    "            categories[cat] = categories.get(cat, 0) + 1\n",
    "        \n",
    "        print(f\"\\nTop categories:\")\n",
    "        sorted_cats = sorted(categories.items(), key=lambda x: x[1], reverse=True)\n",
    "        for cat, count in sorted_cats[:15]:\n",
    "            print(f\"  {cat}: {count}\")\n",
    "        \n",
    "        # Detection method summary\n",
    "        detection_stats = {}\n",
    "        for alg in merged_algorithms:\n",
    "            methods = [m.strip() for m in alg['detection_method'].split(',')]\n",
    "            for method in methods:\n",
    "                detection_stats[method] = detection_stats.get(method, 0) + 1\n",
    "        \n",
    "        print(f\"\\nDetection methods:\")\n",
    "        for method, count in sorted(detection_stats.items()):\n",
    "            print(f\"  {method}: {count}\")\n",
    "        \n",
    "        return len(merged_algorithms)\n",
    "    else:\n",
    "        print(\" No QGIS algorithms found\")\n",
    "        return 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    total = export_qgis_algorithms()\n",
    "    print(f\"\\nFinal count: {total} QGIS algorithms catalogued\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dc3c83-d486-4d04-81c7-92e4ea763869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
